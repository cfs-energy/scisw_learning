{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee751e7",
   "metadata": {},
   "source": [
    "### 06 - Packaging\n",
    "\n",
    "#### Outline\n",
    "* Guidelines\n",
    "* Recommended Stack & Template Package\n",
    "* Dependency Mgmt\n",
    "* Linting & Formatting\n",
    "* Testing\n",
    "* Typechecking\n",
    "* Continuous Integration (CI)\n",
    "* Repo Configuration\n",
    "* Publishing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf8bd17",
   "metadata": {},
   "source": [
    "----\n",
    "#### Guidelines\n",
    "\n",
    "These evolve over time as the field of software continues to change.\n",
    "\n",
    "Key points\n",
    "* Quality only goes up: use automated tools to prevent backsliding and decay without excessive time commitment\n",
    "* Use semver to reduce unexpected breaking changes\n",
    "* Always keep track of units-of-measure\n",
    "* Design reviews are important but don't need to be bureaucratic - just look over the design of large projects with a friend before you start work\n",
    "* No new development in closed-source or obsolete languages except for interfacing with necessary dependencies in those languages\n",
    "\n",
    "Notice that this doesn't include any specifics about _how_ these goals should be achieved. **The point isn't to use a tool, it's to produce quality software.** It does not matter what tools you use as long as your code is reliable, maintainable, documented, accessible, and performant.\n",
    "\n",
    "That said, we can certainly recommend some specifics that are known to work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00043d",
   "metadata": {},
   "source": [
    "----\n",
    "#### Recommended Stack & Template Package\n",
    "\n",
    "Python package management tools are fairly fragmented.<br>As a notable contrast, in Rust, all of these functions and more are covered by a single tool (cargo).\n",
    "\n",
    "| Tool | Purpose |\n",
    "|------|---------|\n",
    "|github or gitlab| version control & CI runner |\n",
    "| uv | dependency mgmt |\n",
    "| hatchling | build backend |\n",
    "| ruff | linting & formatting |\n",
    "| pytest<br>pytest-cov<br>mktestdocs | testing |\n",
    "| pyright | typechecking |\n",
    "| mkdocs<br>mkdocs-material<br>mkdocstrings[python] | documentation |\n",
    "| twine | publishing |\n",
    "\n",
    "In addition, there are some common tasks that approach the formality of package management.<br>\n",
    "My recommendations:\n",
    "\n",
    "| Library | Purpose |\n",
    "|---------|---------|\n",
    "| click   | Command Line Interface (CLI) |\n",
    "| plotly dash | Graphical User Interface (GUI) |\n",
    "| rich | Formatted logging |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d19e30",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### Step-By-Step Example\n",
    "\n",
    "##### Initialize\n",
    "1. Make a project folder\n",
    "    * `uv init --lib --no-pin-python <PROJECT_NAME>`\n",
    "2. Add dev-dependencies to pyproject.toml\n",
    "    * Include everything needed for QC/CI tools (linting, testing, docs, etc)\n",
    "    * Usually just copy this block forward from another project\n",
    "3. Add `tests`, `examples`, and `docs` folders\n",
    "    * Add an empty `.placeholder` file in each so that they can be added to the repo\n",
    "4. Add `__version__` parameter in package level `__init__.py`\n",
    "\n",
    "##### Set up QC\n",
    "5. Add linter configuration to `pyproject.toml`\n",
    "6. Add coverage fail-under to `pyproject.toml`\n",
    "7. Add github actions test workflow\n",
    "    * Typecheck, lint, test, build docs\n",
    "8. Add doctesting function in `tests/test_docs.py`\n",
    "9. Add example testing function in `tests/test_examples.py`\n",
    "\n",
    "##### Add Docs\n",
    "9. Copy forward a `mkdocs.yml` and `readthedocs.yml` from another repo\n",
    "10. Make sure the API doc autogenerator is enabled (mkdocstrings[python])\n",
    "11. Update index.md, api.md, and page routing\n",
    "    * Note - items without docstrings will not appear in the docs at all!\n",
    "\n",
    "##### Add Logging\n",
    "12. Add a simple logging layer\n",
    "    * At minimum, include timestamps and stack origin of messages & allow writing to a logfile\n",
    "    * Log major branches in the code at `info` level\n",
    "    * Log suspicous input, output, or internal state at `warning` level\n",
    "    * Log recovery from clearly incorrect state at `error` level\n",
    "\n",
    "##### Add CLI\n",
    "13. Add an executable entrypoint in `pyproject.toml` like\n",
    "```toml\n",
    "[project.scripts]\n",
    "refprpoj = \"refproj.cli:cli\"\n",
    "```\n",
    "14. Add a `cli.py` file in the source folder\n",
    "15. Add a `cli()` function in cli.py and populate it with click decorators\n",
    "16. Add a test of the CLI using click CliRunner\n",
    "\n",
    "##### Add GUI\n",
    "17. Add a `gui.py` source file\n",
    "18. Add a simple dash app in gui.py\n",
    "19. Add a `refproj gui` CLI command\n",
    "\n",
    "##### Set up Github Repo\n",
    "20. Make a new github repo\n",
    "21. Push the existing project to the repo\n",
    "22. Enable actions workflows in the repo settings\n",
    "23. Enable branch protections for `main` branch in repo settings\n",
    "    * Require PRs\n",
    "        * Require passing CI workflows to merge\n",
    "        * Require up-to-date branch before merge\n",
    "    * Do not allow deletion\n",
    "    * Do not allow bypassing rules (this can lead to accidental deletion or modification by admins)\n",
    "\n",
    "##### Finishing Touches\n",
    "24. Add a `CHANGELOG.md` (see other changelogs for examples of formatting conventions)\n",
    "    * Update this changelog with every version\n",
    "    * To reuse the effort of making the changelog entry, use it as the PR description and PR merge commit message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81e94e6",
   "metadata": {},
   "source": [
    "----\n",
    "#### Version Control, CI, and Repo Configuration\n",
    "\n",
    "* Both github and gitlab combine version control, access management, and job-running systems\n",
    "* Honorable mention: Codeberg provides version control and access management, but does not have job-runners\n",
    "  * Instead, it can be integrated with 3rd-party job runners like CircleCI, Jenkins, etc\n",
    "* **Use your CI system to run typechecking, linting, and unit tests**\n",
    "\n",
    "##### Recommended Configuration & Workflows\n",
    "\n",
    "* Versioning strategy\n",
    "  * Semantic versioning is the only responsible choice\n",
    "  * Others are reliability issues\n",
    "  * Maintain a CHANGELOG.md (and reuse the entries for commit messages and PR descriptions)\n",
    "* Commit workflow\n",
    "  * Every commit on `main` is a valid, fully-functioning version of the software\n",
    "  * Commit however often and in whatever way you like on branches\n",
    "  * Squash branch to a single commit before merging to main\n",
    "  * Commit messages on `main` should be the changelog entry\n",
    "* Branch protections for `main`\n",
    "  * No deletion\n",
    "  * Require PRs (even if you are working solo!)\n",
    "  * Require 1 PR approver (ok to enable this after the initial period of rapid development)\n",
    "  * Do not allow admins to bypass rules\n",
    "    * If it's an emergency, they can temporarily switch the configuration\n",
    "    * Disallowing bypass prevents accidental pushes to main\n",
    "* PR workflows\n",
    "  * Working solo: Squash-Merge Only\n",
    "    * Squash-merge breaks connection between `main` and branches; only works if there is only one person working on the project at a time\n",
    "  * With a team: Manually squash branch before merging\n",
    "    * This preserves continuity of history on `main`\n",
    "  * Long-term dev projects: Add a `develop` branch with relaxed quality standard until the smoke clears\n",
    "  * Either way,\n",
    "    * Configure repo to require passing test workflows to merge PR\n",
    "    * Configure repo to require up-to-date branch before merging\n",
    "      * When you merge a PR, the new state of main should be exactly the same as the state of the PR branch! Otherwise, how do you know it isn't going to be broken after the auto-merge?\n",
    "    * PR description can be the changelog entry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f69e530",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### Dependency Mgmt\n",
    "\n",
    "* uv is faster and more reliable than the other options\n",
    "  * They maintain their own pypi metadata database to accelerate solving dependency graph\n",
    "  * Pip by itself can stall semi-permanently on a difficult configuration due to needing to download entire packages to check dep compatibility\n",
    "  * uv can also handle your python installation!\n",
    "* Honorable mention\n",
    "  * Poetry is fairly solid, but slower, less reliable, and less featured than uv\n",
    "  * Just using a bare pyproject.toml is a valid option\n",
    "    * Dep managers provide extra features like dep locking, but aren't strictly required\n",
    "\n",
    "A new project can be initialized with uv by doing\n",
    "\n",
    "```bash\n",
    "uv init --lib --no-pin-python --build-backend=setuptools <MY_PACKAGE_NAME>\n",
    "```\n",
    "\n",
    "with `<MY_PACKAGE_NAME>` replaced with your choice of package name.\n",
    "\n",
    "Then, use uv with your package like:\n",
    "\n",
    "```bash\n",
    "uv sync  # Update lockfile\n",
    "uv pip install -e .  # Install editable dev version\n",
    "uv build  # Generate distribution artifacts (wheel, sdist)\n",
    "uv run --locked <COMMAND>  # Run a command in a uv env that has locked deps (makes CI reliable)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92686436",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### Build Backend\n",
    "\n",
    "Build backends handle assembling your library into a packaged `wheel` (binary) or `sdist` (source) distribution artifact.\n",
    "\n",
    "`uv` defaults to `hatchling`, but as of 2025-06-30 this is still causing sporadic import resolution problems with unknown root cause. To resolve this, setuptools (the original build backend) should be used instead for now.\n",
    "\n",
    "If Rust language bindings are used, the `maturin` build backend can be used to manage compiling and linking PyO3 Rust bindings. The maturin project also provides a github action template for cross-compiling and publishing for different platforms, making it essentially effortless to publish mixed Rust-Python projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd3cace",
   "metadata": {},
   "source": [
    "----\n",
    "#### Linting & Formatting\n",
    "\n",
    "\"Linting\" is essentially spell-checking for code; formatting automatically resolves most linting errors. If you don't lint and format your code, it will look bad, it will be difficult to read, and it will not inspire confidence or trust.\n",
    "\n",
    "Traditionally, Python linters and formatters have been separate entities, and careful configuration was required to produce a self-consistent combination of linter and formatter. This was folly.\n",
    "\n",
    "Ruff provides both linting and formatting, and formats code in a way that is consistent with its own linting. It is also substantially faster than any previous linter or formatter. There is no reason to use another tool for this.\n",
    "\n",
    "Use like\n",
    "\n",
    "```bash\n",
    "ruff format .\n",
    "ruff check . --fix  # Auto-fix structural lints\n",
    "ruff check .  # Check for remaining structural lints\n",
    "```\n",
    "\n",
    "By default, `ruff check` only errors on structural issues, not formatting.<br>\n",
    "Formatting lints can be selected by [adding configuration to the `pyproject.toml`](https://docs.astral.sh/ruff/linter/#__tabbed_2_1):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda3f6a0",
   "metadata": {},
   "source": [
    "----\n",
    "#### Typechecking\n",
    "\n",
    "Python does not natively check correctness of types at runtime,\n",
    "and the language itself provides no tools for checking statically.\n",
    "Instead, an external tool is needed.\n",
    "\n",
    "It is recommended to use a typechecker as early in a project as possible.\n",
    "Without appropriate guidance, it's easy to end up with thousands of type errors\n",
    "that make it difficult to add typechecking late in development.\n",
    "\n",
    "Typecheckers\n",
    "* `pyright`: recommended for now\n",
    "  * Fairly good type inference; not unnecessarily facetious\n",
    "  * Ironically, `pyright`'s package versioning is awful - it regularly has unexpected breaking changes caused by internal javascript deps that can't be pinned by a python dependency manager\n",
    "* `mypy`: works, but incredibly punishing\n",
    "  * Does not infer types; requires complete type hints\n",
    "  * Makes some sections of the language unusable\n",
    "* `ty`: very promising in the future\n",
    "  * Switch to `ty` as soon as it's stable\n",
    "  * It is under construction now, but already maintains a higher standard of quality and performance than other tools\n",
    "  * Just missing some features as of 2025-06-30\n",
    "\n",
    "Run pyright like\n",
    "\n",
    "```bash\n",
    "pyright .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58fb853",
   "metadata": {},
   "source": [
    "----\n",
    "#### Testing\n",
    "\n",
    "In addition to obvious reliability benefits, testing provides progress capture: once you get something working, if it's tested, then it will continue to work in the future. Otherwise, features tend to go stale as things change, they become broken, and go unfixed for long periods of time until the developers forget what caused the breakage and what is needed to fix it.\n",
    "\n",
    "`pytest` provides basic functionality to find and run unit tests.\n",
    "\n",
    "`pytest-cov` extends this to check which lines run and which do not, in order to show gaps in testing.\n",
    "\n",
    "`mktestdocs` provides doctesting, which finds and runs code segments in documentation to ensure that documentation does not go stale.\n",
    "\n",
    "---\n",
    "\n",
    "Coverage testing can run automatically alongside pytest by setting configuration in `pyproject.toml`:\n",
    "\n",
    "```toml\n",
    "[tool.pytest.ini_options]\n",
    "addopts = \"--cov=<project-name> --cov-report html --cov-fail-under=90\"\n",
    "```\n",
    "\n",
    "The fail-under percentage limit is adjustable. 90% is typically a good number to aim for non-safety-critical code. 100% coverage is commendable, but not necessarily the most efficient balance of developer time for every package.\n",
    "\n",
    "Coverage fail-under should\n",
    "not be decreased casually to avoid writing tests. That said, it may be a valid strategy if the newly-added context is extraordinarily difficult to test (for example, GUIs and CLIs frequently do not yield easily to testing). Decreasing coverage percentage is better than writing testable fluff to pad the numbers.\n",
    "\n",
    "---\n",
    "\n",
    "##### Always test your docs!\n",
    "\n",
    "Examples embedded in documentation should be up-to-date at all times, and this can be ensured by using a tool (`mktestdocs`) to find and run code segments in documentation.\n",
    "\n",
    "---\n",
    "\n",
    "##### Always test your examples!\n",
    "\n",
    "There is no excuse for standalone examples to go stale and stop working. Examples should be included in testing so that if a change to the code breaks and example, that change can't be merged into main.\n",
    "\n",
    "Below is a method for testing standalone examples.\n",
    "\n",
    "```python\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import runpy\n",
    "\n",
    "import pytest\n",
    "\n",
    "EXAMPLES_DIR = pathlib.Path(__file__).parent / \"../examples\"\n",
    "EXAMPLES = [\n",
    "    EXAMPLES_DIR / x\n",
    "    for x in os.listdir(EXAMPLES_DIR)\n",
    "    if (os.path.isfile(EXAMPLES_DIR / x) and x[-3:] == \".py\")\n",
    "]\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"example_file\", EXAMPLES)\n",
    "def test_example(example_file: pathlib.Path):\n",
    "    print(example_file)\n",
    "    runpy.run_path(str(example_file), run_name=\"__main__\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d5c803",
   "metadata": {},
   "source": [
    "----\n",
    "#### Continuous Integration (CI)\n",
    "\n",
    "CI historically has a more specific meaning, but now usually refers to the practice of using job-runner clusters to run linting, testing, and publishing of packages automatically.\n",
    "\n",
    "CI configuration varies by provider, but there are common themes. Ultimately, you will rarely write those configs by hand, except sections that represent a bash script.\n",
    "\n",
    "Setting them up involves quite a bit of copy-pasting and troubleshooting, and unfortunately, because the config formats change rapidly and are only just starting to see the appearance of proper language support, AI coding assistants are not yet effective at relieving the boilerplate grind of configuring CI systems.\n",
    "\n",
    "Some pointers for setting up github or gitlab CI\n",
    "* Configure the repo to require passing tests for merging to main\n",
    "* Start from a template, use an auto-generation tool, or copy forward a working config from another repo\n",
    "* Look for examples or prepackaged workflows before handwriting custom ones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6fdf49",
   "metadata": {},
   "source": [
    "----\n",
    "#### Documentation\n",
    "\n",
    "`mkdocs` provides a simple, easy-to-configure, easy-to-write interface for documentation using the ever-popular markdown-with-html format.\n",
    "\n",
    "`mkdocstrings[python]` provides **automatic generation of formatted API docs from your code's docstrings**. This is a very powerful feature, and an excellent way to reuse the effort put into writing docstrings. This also provides a guarantee that the docs will remain up to date with the code at all times.\n",
    "\n",
    "`mkdocs-material` provides excellent styling for mkdocs.\n",
    "\n",
    "`mktestdocs` provides doctesting for markdown files by crawling the files for codeblocks.\n",
    "\n",
    "**Readthedocs** can be used to host mkdocs documentation by pointing it toward the repository. It is best used for public repos, and has only minimal functionality for private doc pages. Github Pages can also be used to host mkdocs sites, and has better features for supporting private company-internal pages.\n",
    "\n",
    "mkdocs has a convenient single-file-config format. That said, it can be hard to start it from scratch, so it's usually best to copy forward a working config from an existing project as long as you know what every part of the config does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc66745",
   "metadata": {},
   "source": [
    "----\n",
    "#### Publishing\n",
    "\n",
    "`twine` is a simple, popular, and reliable tool for publishing distribution artifacts (wheels & sdist) to a package repo.\n",
    "\n",
    "##### Never keep credentials for the public pypi on your local machine\n",
    "\n",
    "Add them as environment secrets in your CI provider and publish from there. That way, there is no possibility of accidentally publishing anything from your local machine, which is especially important if you work with both public and private projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d87087",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "class310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
