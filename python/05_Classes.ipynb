{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee751e7",
   "metadata": {},
   "source": [
    "### 05 - Classes and Decorators\n",
    "\n",
    "#### Outline\n",
    "\n",
    "* Class Definition, Initialization, and Inheritance\n",
    "* Methods, Properties, and Caching\n",
    "* Abstract Base Classes & Protocols\n",
    "* Decorators\n",
    "* Context Objects\n",
    "* Pydantic and Dataclasses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f85b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import (\n",
    "    annotations,\n",
    ")  # Must be at beginning of file; required for self-referencing class method\n",
    "\n",
    "# These are part of the standard library\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "working_directory = Path(\n",
    "    os.path.abspath(\"\")\n",
    ")  # Immediately stuff the string into a Path object\n",
    "static_dir = working_directory / \"static\" / \"05\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00043d",
   "metadata": {},
   "source": [
    "----\n",
    "#### Class Definition, Initialization, and Inheritance\n",
    "\n",
    "Classes are a combination of data and functions that can be performed on the data.\n",
    "\n",
    "Inheritance can be useful but messy.\n",
    "\n",
    "As a rule of thumb (but not a death pact),\n",
    "* Don't use multiple inheritance unless the second superclass is a primitive\n",
    "  * Sometimes the usage is specifically required by an API (like Qt); this is a red flag, but sometimes you just need to power through\n",
    "* Don't use multiple levels of inheritance (two levels ok if the first level is an abstract class)\n",
    "\n",
    "Inheriting classes carry all of the baggage (extra methods, stored fields, etc) of their ancestor classes. If used in excess, this can bloat both the complexity and RAM usage of a system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2120de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the class definition\n",
    "class Example:\n",
    "    \"\"\"Classes should also have a docstring describing what they do\"\"\"\n",
    "\n",
    "    # These are class attributes.\n",
    "    # NOTE: Similar to functions, we can assign a default here,\n",
    "    # and that default will be shared among all instances,\n",
    "    # so we have to remember to avoid mutable default arguments.\n",
    "    a: list[float]\n",
    "    \"\"\"A list of stuff\"\"\"  # Attributes can and should have a docstring\n",
    "    b: int\n",
    "    \"\"\"A number of things\"\"\"\n",
    "    c: float\n",
    "    \"\"\"How much stuff\"\"\"\n",
    "\n",
    "    # This is a required method, the constructor\n",
    "    def __init__(self, a: list[float], b: int, c: float):\n",
    "        \"\"\"The init function docstring is the one people will see when they mouse-over the class name\n",
    "\n",
    "        Args:\n",
    "            a: _description_\n",
    "            b: _description_\n",
    "            c: _description_\n",
    "        \"\"\"\n",
    "        # These are instance attributes\n",
    "        # Best-practice is for these to always match a declaration of a class attribute,\n",
    "        # but syntax does not impose this requirement\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "        print(\"Example init\")\n",
    "\n",
    "    # This is an instance method\n",
    "    def bc(self) -> float:\n",
    "        \"\"\"b times c\"\"\"\n",
    "        return self.b * self.c\n",
    "\n",
    "\n",
    "# These are instances\n",
    "e1 = Example([1.0], 3, 7.0)  # This is calling Example.__init__()\n",
    "e2 = Example([2.0, 4.3], 1, 0.0)\n",
    "\n",
    "# We can access attributes and call functions\n",
    "print(f\"e1.a: {e1.a}\")\n",
    "print(f\"e2.a: {e2.a}\")\n",
    "print(f\"e1.bc() = {e1.bc()}\")\n",
    "print(f\"e2.bc() = {e2.bc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83678ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is inheritance\n",
    "import json\n",
    "\n",
    "\n",
    "# We can inherit from the class we defined (or anything else)\n",
    "class HashableExample(Example):\n",
    "    \"\"\"A wrapper for `Example` that does explicit hashing based on attr values rather than address\"\"\"\n",
    "\n",
    "    def __init__(self, a: list[float], b: int, c: float):\n",
    "        # Call superclass's constructor, otherwise its part of the functionality will not work\n",
    "        # NOTE: Show what happens if we remove super init\n",
    "        super().__init__(a, b, c)\n",
    "        print(\"HashableExample init\")\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        \"\"\"Inefficient but effective method for hashing this type\"\"\"\n",
    "        return hash(json.dumps({\"id\": id(self), \"a\": self.a, \"b\": self.b, \"c\": self.c}))\n",
    "\n",
    "\n",
    "e3 = HashableExample([1.0], 3, 7.0)\n",
    "\n",
    "emap: dict[HashableExample, int] = {e3: id(e3)}\n",
    "emap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554057e7",
   "metadata": {},
   "source": [
    "----\n",
    "#### Methods, Properties, and Caching\n",
    "\n",
    "Methods\n",
    "* **Instance methods** are functions that belong to a given instance of the class, and take `self` as the first argument\n",
    "* **Class methods** provide functions that can be run without instantiating the class, and take `cls` as the first argument\n",
    "* **Static methods** have no syntactic association with the class, but are grouped with it conceptually\n",
    "\n",
    "Properties\n",
    "* **Properties** act like an attribute, but they run a function when accessed\n",
    "  * This eliminates unary getters and setters\n",
    "* **Cached properties** are run once when accessed, and never again\n",
    "  * This allows constructing implicit dependency trees \n",
    "  * Should only be combined with **frozen** classes! There is no cache invalidation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67972a2",
   "metadata": {},
   "source": [
    "##### Kinds of methods and properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c302ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class MethodsAndPropertiesExample:\n",
    "    \"\"\"\n",
    "    An example of different kinds of methods and properties,\n",
    "    representing a cylinder.\n",
    "    \"\"\"\n",
    "\n",
    "    _radius: float  # relatively-private, get/set with property\n",
    "    \"\"\"[m]\"\"\"\n",
    "    density: float\n",
    "    \"\"\"[kg/m^3]\"\"\"\n",
    "\n",
    "    def __init__(self, radius, density):\n",
    "        self.radius = radius\n",
    "        self.density = density\n",
    "\n",
    "    # Class methods take `cls`, the class, as the first argument rather than an instance of the class\n",
    "    # NOTE: we need future annotations to annotate these properly\n",
    "    @classmethod\n",
    "    def from_density_and_mass_per_length(\n",
    "        cls, density: float, mass_per_length: float\n",
    "    ) -> MethodsAndPropertiesExample:\n",
    "        \"\"\"Back-calculate radius from mass per length and density\n",
    "\n",
    "        Args:\n",
    "            density: [kg/m^3]\n",
    "            mass_per_length: [kg/m]\n",
    "\n",
    "        Returns:\n",
    "            Instance of MethodsAndPropertiesExample\n",
    "        \"\"\"\n",
    "        radius = (mass_per_length / density / np.pi) ** 0.5  # [m]\n",
    "        return cls(radius, density)\n",
    "\n",
    "    # Staticmethods are associated with the class, but don't take either `self` or `cls` arguments.\n",
    "    # They _could_ be standalone functions, but are grouped with the class by choice.\n",
    "    @staticmethod\n",
    "    def cylinder_volume(radius: float, length: float) -> float:\n",
    "        \"\"\"[m^3]\"\"\"\n",
    "        area = np.pi * radius**2  # [m^2]\n",
    "        return area * length\n",
    "\n",
    "    # This is an instance method, which takes `self` (an instance of the class) as its first argument\n",
    "    def mass(self, length: float) -> float:\n",
    "        \"\"\"[kg] mass for a given length\"\"\"\n",
    "        return (\n",
    "            self.section_area * length * self.density\n",
    "        )  # This uses the `section_area` property\n",
    "\n",
    "    # The minimal form of a property only provides a getter function\n",
    "    @property\n",
    "    def mass_per_length(self) -> float:\n",
    "        \"\"\"[kg/m] 1D mass density\"\"\"\n",
    "        return (\n",
    "            MethodsAndPropertiesExample.cylinder_volume(self.radius, 1.0) * self.density\n",
    "        )\n",
    "\n",
    "    # Properties can also specify `setter` and `deleter` functions\n",
    "    @property\n",
    "    def radius(self) -> float:\n",
    "        \"\"\"[m]\"\"\"\n",
    "        return self._radius\n",
    "\n",
    "    @radius.setter\n",
    "    def radius(self, val: float):\n",
    "        if val <= 0.0:\n",
    "            raise ValueError(\"Radius must be positive nonzero\")\n",
    "        else:\n",
    "            self._radius = val\n",
    "\n",
    "    @radius.deleter\n",
    "    def radius(self):\n",
    "        raise AttributeError(\"Radius is a required attribute and must not be deleted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6889d3a",
   "metadata": {},
   "source": [
    "##### Caching\n",
    "\n",
    "Caching, aka memoizing, is the practice of storing results for reuse.\n",
    "\n",
    "Cache invalidation - figuring out when you need to calculate a new value instead of using the stored one - is considered one of the \"very hard problems\" of software engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a48444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cached properties require careful handling because, by default, the cache is never invalidated\n",
    "from functools import cached_property\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)  # Error on assigning to an attribute after init\n",
    "class CachedPropertyExample:\n",
    "    a: float\n",
    "    \"\"\"First value\"\"\"\n",
    "    b: float\n",
    "    \"\"\"Second value\"\"\"\n",
    "\n",
    "    @cached_property\n",
    "    def ab(self) -> float:\n",
    "        \"\"\"a times b. Calculated once, then cached indefinitely.\"\"\"\n",
    "        print(\"Calculating a times b\")\n",
    "        return self.a * self.b\n",
    "\n",
    "    def invalidate_cache(self):\n",
    "        \"\"\"Property caches can be invalidated manually\"\"\"\n",
    "        try:\n",
    "            del self.ab\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "\n",
    "# NOTE: discuss lack of look-through docs on dataclass constructor\n",
    "cpe = CachedPropertyExample(1.0, 2.0)\n",
    "cpe.ab  # NOTE: notice how the spam only prints once\n",
    "cpe.ab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e5641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also cache functions that are not part of a class.\n",
    "# The arguments must be hashable and will be compared by their hash to find a matching cache entry.\n",
    "# Only use this if the function is significantly more expensive than hashing the inputs!\n",
    "from functools import cache, lru_cache\n",
    "\n",
    "\n",
    "@cache  # Unbounded cache size - may run you out of RAM\n",
    "def infinite_cache_func(c: HashableExample) -> float:\n",
    "    # <Some expensive operation>\n",
    "    ...\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=10)\n",
    "def limited_cache_func(c: HashableExample) -> float:\n",
    "    # <Some expensive operation>\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889f46e4",
   "metadata": {},
   "source": [
    "##### Special methods\n",
    "\n",
    "Methods on a class that are enclosed by double underscores are \"special\" or \"magic\" methods, and have some connection to language syntax or builtin functions.\n",
    "\n",
    "All special methods can be overwritten with user-defined functions. This allows implementing things like\n",
    "* Operator overloading\n",
    "* Assignment validation or freezing\n",
    "* Nested data access patterns\n",
    "\n",
    "and much more.\n",
    "\n",
    "The python language does not maintain a list of special functions. I have done my best to collect them here, but there are likely more that I don't know about.\n",
    "\n",
    "| Special Method | Related Builtin | Comments |\n",
    "| -------------- | --------------- | -------- |\n",
    "| `__call__` | `instance(*args, **kwargs)` | Call an instance as a function |\n",
    "| _Identification and representation_ | | \n",
    "| - | `id(instance)` | Get the memory address of an instance of a class |\n",
    "| `__str__` | `str(instance)` | Make a string representation of the instance, usually for display during debugging |\n",
    "| `__repr__` | `repr(instance)` | Nowadays, this is more often used for a storeable string representation like json. Historically, it was used to store all info about the instance as an executable script that rebuilds it from scratch (don't do this, though).  |\n",
    "| _Access_ | | \n",
    "| `__getattribute__(attr)` | `getattr(instance, attr)` | Get the value of an attribute of the class |\n",
    "| `__getattr__(attr)` | `getattr(instance, attr)` | Old syntax; used automatically if `__getattribute__` fails |\n",
    "| `__setattr__(attr, val)` | `setattr(instance, attr, val)` | Set the value of an attribute |\n",
    "| - | `hasattr(instance, attr)` | Check if an instance of a class has an attribute |\n",
    "| `__dict__` | `dict(instance)` | Get a dictionary of all the methods and attributes |\n",
    "| _Collections_ | | |\n",
    "| `__getitem__(key)` | `val = instance[key]` | Indexing and slicing syntax (`key` may be a `slice` object) |\n",
    "| `__setitem__(key)` | `instance[key] = val` |  |\n",
    "| `__contains__(key)` | `key in instance` | |\n",
    "| `__reversed__` | `reversed(instance)` | Get a representation of the instance with the order of elements reversed |\n",
    "| _Iterators_ | | |\n",
    "| `__len__` | `len(instance)` | Get the length of an instance that represents a collection |\n",
    "| `__iter__` | `iter(instance)` | Get an iterator over the instance; the iterator must implement `__next__` |\n",
    "| `__next__` | `next(iterator)` | Get the next value from an iterator or `raise StopIteration` if no elements remain |\n",
    "||||\n",
    "| `__r<op>__`<br>NOTE: all binary operators have a `__r<op>__` right-side variant like `__radd__` that is used if the left-side operation fails. Among other things, this allows supporting bidirectional logic in custom numeric types, which is essential for things like symbolics and autodiff tracers. | | |\n",
    "| `__i<op>__`<br>NOTE: all binary operators that support compound assignment like `a *= b` have an `__i<op>__` variant that defines operate-assign behavior. |\n",
    "||||\n",
    "| _Math operators_ | | |\n",
    "| `__add__` | `self + other` | |\n",
    "| `__sub__` | | |\n",
    "| `__mul__` | | |\n",
    "| `__truediv__` | | New syntax for division python 3+ |\n",
    "| `__pow__` | `self ** other` | |\n",
    "| `__floordiv__` | `self // other` | Floor-rounding division |\n",
    "| `__mod__` | `self % other` | modulo (remainder) operator |\n",
    "| `__neg__` | `-instance` | unary negation |\n",
    "| `__pos__` | `+instance` | unary positiv...ation? |\n",
    "| `__invert__` | `~instance` | unary positive-negative inversion |\n",
    "| _Logical operators_ | | Note it is not possible to overload `and` and `or` logical operators in python |\n",
    "| `__eq__` | `self == other` | |\n",
    "| `__gt__` | `self > other` | |\n",
    "| `__lt__` | `self < other` | |\n",
    "| `__le__` | `self <= other` | |\n",
    "| `__ge__` | `self >= other` | |\n",
    "| `__ne__` | `self != other` | |\n",
    "| _Bitwise operators_ | | |\n",
    "| `__or__` | `self \\| other` | bitwise-or |\n",
    "| `__and__` | `self & other` | bitwise-and |\n",
    "| `__xor__` | `self ^ other` | bitwise exclusive or |\n",
    "| `__not__` | `~instance` | bitwise-not |\n",
    "| _Context objects_ | | |\n",
    "| `__enter__` | `with instance as local_name:` | Enter a context |\n",
    "| `__exit__(self, exc_type, exc_value, traceback)` | | Called unconditionally on exiting the context |\n",
    "| _Descriptor objects_ | | Descriptor objects allow implicitly defining things like properties. This is uncommon to see used. They have their own special methods, which are left out of this table.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dc07d6",
   "metadata": {},
   "source": [
    "----\n",
    "#### Abstract Base Classes and Protocols\n",
    "\n",
    "* `ABC` enforces that subclasses must implement certain interface methods or properties\n",
    "  * This allows specifying that subclasses should _behave in a certain way_ without being too specific about how that is achieved\n",
    "* `Protocol` implicitly indicates that any class that _already_ implements certain methods or properties can be considered to be an instance of that protocol\n",
    "  * `Protocol` does not work well with pydantic, dataclasses, typechecking, or basically anything else, and is not recommended for use\n",
    "  * Names of fields and arguments have to match exactly to pass typechecking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918488ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Self  # python 3.11+\n",
    "from typing_extensions import Self  # Python 3.10- backport\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class ExampleAbstractBase(ABC):\n",
    "    @abstractmethod\n",
    "    def must_implement_method(self, other: Self) -> Self:\n",
    "        \"\"\"Join `other` with self\"\"\"\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def method_with_default_impl(self) -> str:\n",
    "        return str(self)\n",
    "\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def must_implement_classmethod(cls, repr: str) -> Self: ...\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def must_implement_property(self): ...\n",
    "\n",
    "    @must_implement_property.setter\n",
    "    def must_implement_property(self): ...\n",
    "\n",
    "\n",
    "# NOTE: show autocomplete for methods & docstring inherited from parent\n",
    "class ExampleConstrained(ExampleAbstractBase):\n",
    "    joined: list\n",
    "    \"\"\"Instances joined with this one\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.joined = []\n",
    "\n",
    "    def must_implement_method(self, other) -> Self:\n",
    "        self.joined.append(other)\n",
    "        return self\n",
    "\n",
    "    def method_with_default_impl(self):\n",
    "        return super().method_with_default_impl()\n",
    "\n",
    "    # And so on\n",
    "    ...\n",
    "\n",
    "\n",
    "# NOTE: We did not define all required functions here, but it doesn't error on the class definition!\n",
    "#       The error will happen on the first attempt to initialize an instance of the class\n",
    "try:\n",
    "    ExampleConstrained()\n",
    "except TypeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7209f5ea",
   "metadata": {},
   "source": [
    "----\n",
    "#### Decorators\n",
    "\n",
    "Decorators are function wrappers. They are a function-of-a-function that returns a new, transformed, function.\n",
    "\n",
    "This can be used to perform logging or instrument a program or to add new features (like caching or symbolic expression mapping) to an existing function.\n",
    "\n",
    "In addition to operating on functions like `def decorator(func)`, decorators can also operate on instance methods, class methods, and classes in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745fdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic decorators are just a function that returns a function,\n",
    "# but by default, they wipe out the docstring and type annotations\n",
    "# of the original\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def my_decorator(f: Callable) -> Callable:\n",
    "    \"\"\"A minimal decorator\"\"\"\n",
    "    print(\n",
    "        \"This part runs when the decorator is applied to a function (during module import)\"\n",
    "    )\n",
    "\n",
    "    def f_wrapped(*args, **kwargs):\n",
    "        \"\"\"A wrapped function\"\"\"\n",
    "        print(f\"Running wrapped function with: {args}\")\n",
    "        return f(*args, **kwargs)\n",
    "\n",
    "    return f_wrapped\n",
    "\n",
    "\n",
    "@my_decorator\n",
    "def my_function(a: int) -> int:\n",
    "    \"\"\"A minimal function\"\"\"\n",
    "    return a**2\n",
    "\n",
    "\n",
    "# NOTE: show that type hints are erased in mouseover\n",
    "print(\"The wrapper runs as expected:\")\n",
    "my_function(5)\n",
    "print(\"...but the docstring of the original function is lost:\")\n",
    "print(my_function.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa190aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorators that preserve docstring and type hints\n",
    "from functools import wraps\n",
    "from typing import Callable, ParamSpec, TypeVar  # Python 3.10+\n",
    "\n",
    "P = ParamSpec(\"P\")\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "\n",
    "def my_decorator_2(f: Callable[P, T]) -> Callable[P, T]:  # This preserves type hints\n",
    "    \"\"\"A better decorator\"\"\"\n",
    "    print(\n",
    "        \"This part runs when the decorator is applied to a function (during module import)\"\n",
    "    )\n",
    "\n",
    "    @wraps(f)  # This preserves docs\n",
    "    def f_wrapped(*args: P.args, **kwargs: P.kwargs) -> T:  # This preserves type hints\n",
    "        \"\"\"A better wrapped function\"\"\"\n",
    "        print(f\"Running wrapped function with: {args}\")\n",
    "        return f(*args, **kwargs)\n",
    "\n",
    "    return f_wrapped\n",
    "\n",
    "\n",
    "@my_decorator_2\n",
    "def my_function_2(a: int) -> int:\n",
    "    \"\"\"A minimal function\"\"\"\n",
    "    return a**2\n",
    "\n",
    "\n",
    "# NOTE: show that type hints are restored in mouseover\n",
    "print(\"The wrapper runs as expected:\")\n",
    "my_function_2(5)\n",
    "print(\"...and it even has the original type hints and docstring:\")\n",
    "print(my_function_2.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c728b3eb",
   "metadata": {},
   "source": [
    "----\n",
    "#### Context Managers\n",
    "\n",
    "Context managers provide a setup-and-teardown pattern. They are used primarily to manage resources outside the program, such as file pipes and connections to non-Python objects, for example, C drivers for a USB device.\n",
    "\n",
    "A context object is any class that implements `__enter__` and `__exit__` methods. `__exit__` _always_ runs, even if there is an exception raised, much like a `finally` block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc3fce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyContext:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"This is called when we enter a `with` scope\"\"\"\n",
    "        print(\"Entering context\")\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        \"\"\"\n",
    "        This is called when we leave the `with` scope, even if there is an exception raised,\n",
    "        much like a `finally` statement.\n",
    "        \"\"\"\n",
    "        print(f\"Exiting context with exception info: {exc_type, exc_value, traceback}\")\n",
    "\n",
    "\n",
    "with MyContext() as ctx:\n",
    "    print(\"Doing stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0075e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with MyContext() as ctx:\n",
    "        print(\"Doing stuff in inner scope\")\n",
    "        raise ValueError(\"oops!\")\n",
    "\n",
    "except ValueError:\n",
    "    print(\"Captured ValueError in outer scope\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddcaab0",
   "metadata": {},
   "source": [
    "----\n",
    "#### Pydantic and Dataclasses\n",
    "\n",
    "* Dataclasses are useful if all you want is immutability or to automate generating the `__init__` function\n",
    "  * Nested dataclasses become nonfunctional rapidly - this is not a real path to robust serialization capability\n",
    "* Pydantic provides that along with tools for validation, initialization, run-time typechecking, serialization/deserialization, and more\n",
    "  * Use pydantic for anything that will be nested, use defaults on mutable types, need serialization/deserialization, typechecking, etc\n",
    "  * Also provides much better look-through/mouseover docs\n",
    "  * Can be extended to handle array data\n",
    "  * Pydantic classes can be autogenerated from an OpenAPI json spec using `datamodel-code-generator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e00495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling numpy arrays in pydantic\n",
    "\n",
    "import numpy as np\n",
    "from pydantic import ConfigDict\n",
    "from pydantic_numpy.model import NumpyModel\n",
    "from pydantic_numpy.typing import NpNDArray  # Array of any type or dimensionality\n",
    "\n",
    "\n",
    "class SerializableWithArray(NumpyModel):\n",
    "    model_config = ConfigDict(validate_assignment=True, frozen=False, extra=\"forbid\")\n",
    "\n",
    "    metadata: dict[str, str]\n",
    "    arr1: NpNDArray\n",
    "    arr2: NpNDArray\n",
    "\n",
    "\n",
    "d = SerializableWithArray(\n",
    "    metadata={\"hello\": \"arrays\"}, arr1=np.ones(2), arr2=np.zeros(2)\n",
    ")\n",
    "d_serialized = d.model_dump_json(indent=2)\n",
    "d_deserialized = SerializableWithArray.model_validate_json(d_serialized)\n",
    "print(d_serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820dba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic with numpy and pint\n",
    "\n",
    "from pydantic import Field, model_validator\n",
    "from pint import Quantity, UnitRegistry\n",
    "from typing import Union, Any\n",
    "\n",
    "ureg = UnitRegistry()\n",
    "Q_ = ureg.Quantity\n",
    "\n",
    "\n",
    "class SerializableQuantity(NumpyModel):\n",
    "    model_config = ConfigDict(validate_assignment=True, frozen=False, extra=\"forbid\")\n",
    "    \n",
    "    # NOTE: discuss tagged vs. untagged unions\n",
    "    magnitude: Union[float, NpNDArray] = Field(union_mode=\"left_to_right\")\n",
    "    units: str\n",
    "\n",
    "    @model_validator(mode=\"before\")\n",
    "    def validate(v: Any) -> Any:\n",
    "        # Allow assigning a Quantity to a field of this type\n",
    "        if isinstance(v, Quantity):\n",
    "            return {\"magnitude\": v.m, \"units\": str(v.units)}\n",
    "        else:\n",
    "            return v\n",
    "\n",
    "    def as_quantity(self) -> Quantity:\n",
    "        return Quantity(self.magnitude, self.units)\n",
    "\n",
    "\n",
    "class UsesSerializableQuantity(NumpyModel):\n",
    "    metadata: dict[str, str]\n",
    "    q1: SerializableQuantity\n",
    "    q2: SerializableQuantity\n",
    "\n",
    "\n",
    "b = UsesSerializableQuantity(\n",
    "    metadata={\"hello\": \"arrays\"}, q1=Q_(1.0, \"m\"), q2=Q_(np.zeros(2), \"kg\")\n",
    ")\n",
    "b_ser = b.model_dump_json(indent=2)\n",
    "b_des = b.model_validate_json(b_ser)\n",
    "print(b_ser)\n",
    "print(b)\n",
    "print(b_des)\n",
    "\n",
    "print(f\"\\nAccess value with units like this: b.q1.as_quantity() = {b.q1.as_quantity()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c21f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation, floats, & discriminated unions\n",
    "from pydantic import BaseModel, EmailStr, field_validator, model_validator\n",
    "from typing import Any, Literal\n",
    "\n",
    "class Left(BaseModel):\n",
    "    kind: Literal[\"left\"] = \"left\"\n",
    "\n",
    "class Right(BaseModel):\n",
    "    kind: Literal[\"right\"] = \"right\"\n",
    "\n",
    "class MyValidated(BaseModel):\n",
    "    \n",
    "    # Simple field validation has shorthand\n",
    "    a: int = Field(gt=0)\n",
    "    # Some common but not-so-simple validations are available as types\n",
    "    b: EmailStr\n",
    "    # Custom validation functions can be provided\n",
    "    c: list[str]\n",
    "    # By default, non-finite numbers are not handled because the json spec doesn't include them\n",
    "    d: float = Field(allow_inf_nan=True)\n",
    "    # Unions can be distinguised by a discriminator field\n",
    "    e: Left | Right = Field(discriminator=\"kind\")\n",
    "\n",
    "    # Some fields can be kept for internal use.\n",
    "    # This field is not serialized or initialized by pydantic,\n",
    "    # and is instead initialized by user code in the after-validator (post-init function).\n",
    "    _f: Callable[[int], str]\n",
    "\n",
    "    @field_validator(\"c\")\n",
    "    @classmethod\n",
    "    def validate_c(cls, v: Any) -> Any:\n",
    "        assert len(v) > 0\n",
    "        return v\n",
    "    \n",
    "    @model_validator(mode=\"before\")\n",
    "    def validate_input(v: Any) -> Any:\n",
    "        # This runs on the inputs before the instance is constructed.\n",
    "        # We can do things like check for software version compatibility here before parsing a json\n",
    "        return v\n",
    "    \n",
    "    @model_validator(mode=\"after\")\n",
    "    def post_init(self) -> MyValidated:\n",
    "        # This runs on an instance after pydantic is done constructing it.\n",
    "        def f(i: int) -> str:\n",
    "            return self.c[i]\n",
    "        self._f = f\n",
    "\n",
    "        return self\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb4716a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "class310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
