{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 - Python Fundamentals Part 2\n",
    "\n",
    "#### Outline\n",
    "\n",
    "* File I/O\n",
    "* Lists, Dictionaries, Loops, and Comprehensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### File I/O\n",
    "\n",
    "Saving and loading files describing inputs, configuration, and results is essential to reproducible and traceable analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are part of the standard library\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# These are libraries that provide \"dataframes\" and CSV I/O\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# These are libraries that provide some nested-structure I/O\n",
    "import json\n",
    "import yaml\n",
    "import pydantic\n",
    "from pydantic import BaseModel  # Good library\n",
    "\n",
    "# Scipy provides matlab I/O\n",
    "from scipy.io import savemat\n",
    "\n",
    "working_directory = Path(os.path.abspath(''))  # Immediately stuff the string into a Path object\n",
    "static_dir = working_directory / \"static\" / \"02\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Raw Text I/O\n",
    "\n",
    "Files are just a series of bytes.\n",
    "\n",
    "Strings are also a series of bytes.\n",
    "\n",
    "A common way to write files is using strings, which makes them human-inspectable. This is raw text: just some strings.\n",
    "\n",
    "A \"line\" is a common pattern in files, but it's not required. It just makes things easier to handle.\n",
    "\n",
    "Each line ends with a \"newline\" character `\\n`, which is a kind of whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading raw text\n",
    "fpath: Path = static_dir / \"example_text.txt\"\n",
    "with open(fpath, \"r\") as f:  # This prevents leakage!\n",
    "    lines = f.readlines()\n",
    "print(f\"Example file contents:\\n\\n{lines}\")  # Another use of format strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving raw text\n",
    "fpath = static_dir / \"example_text_output.txt\"\n",
    "lines_to_write = [\"this\\n\", \"is\\n\", \"a\\n\", \"file\\n\"]\n",
    "with open(fpath, \"w\") as f:\n",
    "    f.writelines(lines_to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CSV I/O\n",
    "\n",
    "CSV (Comma Separated Value) is a common way to store tables of data that can be read by a human, program, or any spreadsheet software.\n",
    "\n",
    "!! Warning !! if you open a CSV file in Excel, it will round numbers when saved! You may only be able to tell that this has happened if the file is version-controlled!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving CSV data\n",
    "time_s = [1, 2, 3]\n",
    "voltage_V = [3.1, 5.7, 1.2]\n",
    "\n",
    "data = {\"time [s]\": time_s, \"voltage [V]\": voltage_V}\n",
    "\n",
    "# With Pandas\n",
    "df_pandas = pd.DataFrame(data)\n",
    "df_pandas.to_csv(static_dir / \"pandas.csv\", index=False)\n",
    "\n",
    "# With Polars\n",
    "df_polars = pl.DataFrame(data)\n",
    "df_polars.write_csv(static_dir / \"polars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading CSV data\n",
    "import numpy as np  # This is the baseline numerics library\n",
    "\n",
    "# With Pandas or Polars\n",
    "df_pandas_new = pd.read_csv(static_dir / \"polars.csv\")  # Swapped files intentionally\n",
    "df_polars_new = pl.read_csv(static_dir / \"pandas.csv\")\n",
    "\n",
    "print(df_pandas_new[\"time [s]\"])\n",
    "\n",
    "assert np.all(df_pandas.values == df_pandas_new.values)\n",
    "assert np.all(df_polars.to_numpy() == df_polars_new.to_numpy())\n",
    "\n",
    "# With numpy\n",
    "vals = np.genfromtxt(static_dir / \"polars.csv\", delimiter=\",\", skip_header=1)\n",
    "assert np.all(vals == df_pandas.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### JSON I/O\n",
    "\n",
    "JSON (JavaScript Object Notation) files are a common way to store data that looks like nested dictionaries or lists.\n",
    "\n",
    "It is a productive way to encode and store configuration, settings, checkpoint data, and some results.\n",
    "\n",
    "It is also commonly used as an inter-language communication medium (for example, to communicate between a client and server).\n",
    "\n",
    "JSON also stores only a limited number of bits of precision for 64-bit floats (53 bits) because this is the point where float resolution exceeds 1.0 and integers are no longer representable. \n",
    "\n",
    "In practice, this is rarely a problem. 53 is already a lot of bits - enough to represent individual nanoseconds for about 3 months, or individual seconds for 285 million years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember this dictionary from before?\n",
    "stuff: dict[str, str] = {\n",
    "    \"foo\": \"bar\",\n",
    "    \"bar\": \"baz\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save it as a json!\n",
    "fpath = static_dir / \"stuff.json\"\n",
    "with open(fpath, \"w\") as f:\n",
    "    f.write(json.dumps(stuff, indent=4))\n",
    "\n",
    "# ... and load it from json!\n",
    "with open(fpath, \"r\") as f:\n",
    "    stuff_reloaded: dict[str, str] = json.loads(f.read())\n",
    "\n",
    "assert stuff == stuff_reloaded\n",
    "\n",
    "# JSON is just a string! We can carry it around internally\n",
    "print(json.dumps(stuff, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't have to handle json I/O by hand - we can define structures and let pydantic do it\n",
    "import pydantic\n",
    "\n",
    "# Define a \"schema\" which is the shape of the data\n",
    "class MyStuff(pydantic.BaseModel):\n",
    "    the_stuff: dict[str, str]\n",
    "    the_number: float\n",
    "\n",
    "    def myfunc(self) -> float:\n",
    "        return self.the_number * 5.0\n",
    "\n",
    "# Make a concrete instance of the data\n",
    "my_stuff: MyStuff = MyStuff(the_stuff=stuff, the_number=3.14)\n",
    "\n",
    "# Write to json string!\n",
    "print(my_stuff.model_dump_json(indent=4))\n",
    "\n",
    "# Load from json string!\n",
    "json_string: str = my_stuff.model_dump_json(indent=4)\n",
    "my_stuff_reloaded: MyStuff = MyStuff.model_validate_json(json_string)\n",
    "\n",
    "# Refer to fields and methods\n",
    "print(my_stuff_reloaded.myfunc())\n",
    "\n",
    "assert my_stuff == my_stuff_reloaded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YAML I/O\n",
    "\n",
    "YAML (YAML Ain't Markup Language) is similar to JSON, but sometimes it looks nicer, and it can represent full float precision. It also includes some templating features that we won't discuss here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# We can convert a dictionary to a yaml just like json\n",
    "yaml_string: str = yaml.safe_dump(stuff)\n",
    "print(yaml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also load a json and swap to yaml\n",
    "data_loaded_from_json: dict[str, str] = json.loads(json_string)\n",
    "yaml_from_json: str = yaml.safe_dump(data_loaded_from_json)\n",
    "print(yaml_from_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... or load yaml and swap to json\n",
    "data_loaded_from_yaml: dict[str, str] = yaml.safe_load(yaml_from_json)\n",
    "json_from_yaml: str = json.dumps(data_loaded_from_yaml, indent=4)\n",
    "\n",
    "assert data_loaded_from_json == data_loaded_from_yaml\n",
    "\n",
    "print(json_from_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TOML I/O\n",
    "\n",
    "TOML (Tomâ€™s Obvious Minimal Language) is similar to JSON and YAML. It is more commonly used for configuring tools, especially low-level utilities, because it is simpler than the others, and it is very very easy to write a parser for TOML as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml  # Pretty good library\n",
    "\n",
    "my_stuff_dict = json.loads(my_stuff.model_dump_json())\n",
    "toml_string = toml.dumps(my_stuff_dict)\n",
    "print(toml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MATLAB I/O\n",
    "\n",
    "Sometimes you don't have time to rewrite all that matlab.\n",
    "\n",
    "Matlab can call Python functions, and directly take ownership of primitives returned from those functions.\n",
    "\n",
    "For arrays and matrices, Python can write `.mat` files that matlab can read.\n",
    "\n",
    "`.mat` files are HDF5-formatted compressed nested data structures. The HDF5 system is incredibly unreliable due to DLL naming overlap and should be avoided when possible - use `zarr` instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "from scipy import sparse\n",
    "\n",
    "dense_array: np.typing.NDArray = np.array([1.0, 3.0, 2.0])\n",
    "dense_mat: np.typing.NDArray = np.diag(dense_array)\n",
    "sparse_mat: sparse.csc_matrix = sparse.csc_matrix(dense_mat)  # Not the most efficient way to do this\n",
    "\n",
    "# Pack stuff to put in the file\n",
    "mat_data = {\n",
    "    \"dense_array\": dense_array,\n",
    "    \"dense_mat\": dense_mat,\n",
    "    \"sparse_mat\": sparse_mat,\n",
    "    \"some_number\": 3.14\n",
    "}\n",
    "\n",
    "savemat(static_dir / \"mat_from_python.mat\", mat_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists, Dictionaries, and Comprehensions\n",
    "\n",
    "Types that represent a pile of stuff are called \"collections.\"\n",
    "\n",
    "Different collections have different benefits and drawbacks.\n",
    "\n",
    "Some collections can be built using shorthand notation called \"comprehension,\" which is essentially Set-Builder Notation written out in words.\n",
    "\n",
    "Some collections are technically faster to access than others. This almost never matters in Python, so don't worry about it unless your stuff is so slow that it doesn't work.\n",
    "\n",
    "| Type ----- | Access | Pros and Cons | Comprehension Pattern |\n",
    "|------|--------|---------------|-----------------------|\n",
    "| List[T] | O(1), ordered, fast constant term | Fast to access, slow to add elements; index by numbers | `[x for x in y]` |\n",
    "| Dict[K, V] | O(1), ordered, slow constant term | Medium to access, medium to add elements; index by anything | `{key: value for key, value in y}` |\n",
    "| Set[T] | One does not access. O(1) to check if a value is in the set | Guarantees uniqueness of members | `{x for x in y}` |\n",
    "| numpy NDArray[T] | O(1), fast iterators | Like a list, but it can do math | `np.array([x for x in y])` |\n",
    "\n",
    "There are many more, but these are enough for most uses.\n",
    "\n",
    "Compared to matlab,\n",
    "* Python indexes from zero, so the first element is list[0] not list[1]\n",
    "* Python uses square brackets for indexing (to distinguish from function calls, which use parentheses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List assembly\n",
    "\n",
    "mylist = [1, 2, 3]  # Direct\n",
    "mylist_2 = [x + 1 for x in range(3)]  # Iterator and comprehension\n",
    "mylist_3 = []  # Incremental is slow for larger uses\n",
    "for i in range(3):  # `range` makes an iterator\n",
    "    mylist_3.append(i + 1)  # List gets re-allocated every few elements\n",
    "\n",
    "print(mylist)\n",
    "print(mylist_2)\n",
    "print(mylist_3)\n",
    "\n",
    "# You can't access an index before it exists,\n",
    "# so you can't assemble a list this way\n",
    "try:\n",
    "    mylist_4 = []\n",
    "    for i in range(3):\n",
    "        mylist_4[i] = i + 1  # Breaks because list[i] does not exist\n",
    "except:\n",
    "    print(\"Noop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List access\n",
    "\n",
    "mylist[0]  # Direct indexing\n",
    "\n",
    "print(\"Direct iteration on list items\")\n",
    "for x in mylist:  # As an iterator\n",
    "    print(x)\n",
    "\n",
    "print(\"\\nComprehension over an existing list to make a new list\")\n",
    "print([x * 5 for x in mylist])\n",
    "\n",
    "print(\"\\nDirect indexing in a range loop\")\n",
    "for i in range(len(mylist)):\n",
    "    print(f\"At index {i}, we have {mylist[i]}\")\n",
    "\n",
    "# Slicing\n",
    "print(\"\\nSlice access to list\")\n",
    "print(mylist[1:]) # Values after and including element 1\n",
    "print(mylist[:1]) # Values before element 1\n",
    "print(mylist[:-1]) # Values up to one before the end\n",
    "print(mylist[1:-1])  # Values in the middle minus the ends\n",
    "print(mylist[::-1])  # Values in reverse\n",
    "print(mylist[::2])  # Every second element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting with the builtin method `sorted`\n",
    "\n",
    "print(sorted(mylist))\n",
    "print(sorted(mylist[::-1]))  # Reverse then sort\n",
    "\n",
    "# Sorting can also be done with a custom comparison key\n",
    "import numpy as np\n",
    "\n",
    "rand1 = np.random.uniform(0, 1, 10).reshape((5, 2)).tolist()  # List of random pairs\n",
    "print(\"\\nUnsorted:                       \", rand1)\n",
    "print(\"Sorted by first element of pair:\", sorted(rand1, key = lambda x: x[0]))  # Sort by the first element of each pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary assembly\n",
    "# Dictionaries are also called maps (hashmaps in this case), which, uh, helps for presenting\n",
    "keys = [\"a\", \"c\", \"b\"]\n",
    "values = [1, 3, 2]\n",
    "\n",
    "mymap = {\"a\": 1, \"c\": 3, \"b\": 2}  # Direct notation; ordered result\n",
    "mymap_2 = dict(a=1, c=3, b=2)  # Function initializer; not necessarily ordered\n",
    "mymap_3 = {k: v for k, v in zip(keys, values)}  # `zip` makes an iterator over pairs of values\n",
    "\n",
    "# For dictionaries, we can assign directly to an entry that doesn't exist yet\n",
    "mymap_4 = {}\n",
    "for i in range(len(keys)):\n",
    "    k = keys[i]\n",
    "    v = values[i]\n",
    "    mymap_4[k] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary access\n",
    "\n",
    "one = mymap[\"a\"]  # Direct access\n",
    "items = [(k, v) for k, v in mymap.items()]  # As an iterator in a comprehension\n",
    "\n",
    "# In a loop over the keys, values, or both\n",
    "print(\"\\nKey iterator\")\n",
    "for k in mymap.keys():\n",
    "    print(k)\n",
    "\n",
    "print(\"\\nValue iterator\")\n",
    "for v in mymap.values():\n",
    "    print(v)\n",
    "\n",
    "print(\"\\nItems -> both keys and values\")\n",
    "for k, v in mymap.items():\n",
    "    print(k, v)\n",
    "\n",
    "# Accessing a member of a dictionary that doesn't exist is an error\n",
    "print(\"\\nAccessing non-existent item\")\n",
    "try:\n",
    "    mymap[\"wassup\"]\n",
    "except:\n",
    "    print(\"noop\")\n",
    "\n",
    "# We can use a fallible method for access if we're not sure whether the item is there or not\n",
    "print(\"\\nFallible access to non-existent member\")\n",
    "k = \"wassup\"\n",
    "val_not_here: int | None = mymap.get(k)\n",
    "print(f\" The value at `{k}` is missing:\", val_not_here)\n",
    "val_is_here: int | None = mymap.get(\"a\")\n",
    "print(\" The value at `a` is present:\", val_is_here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets are mostly useful for assembling unique members\n",
    "\n",
    "mylist_repetitive = [2, 1, 1, 1, 3, 3]\n",
    "list(set(mylist_repetitive))  # Note this is not in the same order!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays are similar to matlab - lists or matrices of values that can do math\n",
    "# BUT multiplication is elementwise by default, and when matrix sizes don't match, an error is produced.\n",
    "\n",
    "arr1 = np.array([x for x in range(5)]) # 5 numbers from 0 to 4\n",
    "arr2 = np.random.uniform(0, 1, 5)  # 5 random numbers between 0 and 1\n",
    "\n",
    "# Array mult ----------------- Matrix mult\n",
    "arr1 * arr2       == np.diag(arr1) @ np.atleast_1d(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "class310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
