{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d52ff853",
   "metadata": {},
   "source": [
    "### 04 - Libraries\n",
    "\n",
    "#### Outline\n",
    "\n",
    "* Performance: clocks, timeit, cProfile, & snakeviz\n",
    "* Numerics: numpy & scipy\n",
    "* Plotting: matplotlib & plotly\n",
    "* Autodiff: Jax, Casadi, and Aerosandbox\n",
    "* Symbolics\n",
    "* Fluid Properties\n",
    "\n",
    "#### Commentary\n",
    "\n",
    "There are tons of fantastic libraries for python! The ones listed here are just a selection of essentials.\n",
    "\n",
    "Later in the class, we'll examine more specialized ones for numerical methods, optimization, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f1a461",
   "metadata": {},
   "source": [
    "----\n",
    "#### Performance\n",
    "\n",
    "Most of the time, you don't need to worry about performance. Computers are very, very fast.\n",
    "\n",
    "That said, especially for numerical work, we often run into problems where if we don't make time for performance, it will make time for itself.\n",
    "\n",
    "The key thing is to **_make sure you are optimizing for a reason_** - if you'll only run a script once and it's fast enough, time spent making it faster **may be wasteful**.\n",
    "\n",
    "Some patterns to look out for, and what to do instead:\n",
    "\n",
    "| Pattern | Alternative |\n",
    "|---------|-------------|\n",
    "| Looping over arrays to do math one element at a time in python | Use array broadcasting |\n",
    "| Nested for-loops to handle 2D+ data | Flatten & reshape if the calc supports it |\n",
    "| Factorial recombination of cases | Monte Carlo or optimization |\n",
    "\n",
    "There are, of course, plenty of other ways to find low-performing code and optimize out from under it.\n",
    "\n",
    "Python isn't a common target for high-effort performance optimization - usually, the pattern is to profile Python code, find the expensive bits, and figure out how to get those to run in a compiled language instead (usually using numpy, which is written in C). Tools for compiled languages, like disassembly, valgrind/cachegrind, strace, perf, and so on, find minimal utility in examining Python scripts.\n",
    "\n",
    "To that end, the main tools are:\n",
    "* time.monotonic_ns - direct-ish access to CPU perf counter (monotonic clock). Just check how long things take!\n",
    "* timeit.timeit - simple benchmarking utility\n",
    "* cProfile & snakeviz - flame charts of profile results for finding what's really important\n",
    "* pyinstrument - ergonomic call-stack profiler/visualizer combining most of cProfile+snakeviz\n",
    "\n",
    "All of these tools are for **_measuring performance_** - if you take one thing away from this, it should be that when you do optimize code, it should be **based on real evidence and measurements** that indicate that the effort will be of value.\n",
    "\n",
    "Don't spend effort guessing what's slow and optimizing the wrong thing when you can just check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d73db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: E731\n",
    "# ^ disables lint on assigning lambda\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from time import monotonic_ns\n",
    "\n",
    "from timeit import timeit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "working_directory = Path(\n",
    "    os.path.abspath(\"\")\n",
    ")  # Immediately stuff the string into a Path object\n",
    "static_dir = working_directory / \"static\" / \"04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some test data\n",
    "a = np.random.uniform(-1.0, 1.0, 100)\n",
    "b = np.random.uniform(-1.0, 1.0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d00e73",
   "metadata": {},
   "source": [
    "##### Monotonics\n",
    "\n",
    "`time.perf_counter_ns` is a simple interface to a monotonic clock that is fast to access and never runs backward, also called a \"perf counter.\"\n",
    "\n",
    "Normal date/time clocks (\"realtime\") can run backward briefly and may be slow to access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e09850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this a few times and look at the noise! Different number every time\n",
    "start_ns = monotonic_ns()\n",
    "np.outer(a, b)\n",
    "end_ns = monotonic_ns()\n",
    "\n",
    "dt = (end_ns - start_ns) / 1e9\n",
    "print(f\"Finished in {dt:2e} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7e068e",
   "metadata": {},
   "source": [
    "##### Timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aefc656",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "# This is some convenient jupyter notebook \"magic\" for running timeit to benchmark the contents of a cell\n",
    "\n",
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e97621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to see how things change, we can use timeit directly,\n",
    "# which lets us see the regime transitions from scalar to vector to overrun\n",
    "\n",
    "n = 10000  # Number of benchmarks\n",
    "\n",
    "sizes = np.logspace(1, 6, 10)\n",
    "times = []\n",
    "\n",
    "for size in sizes:\n",
    "    # Careful not to include initialization in the benchmark!\n",
    "    a = np.random.uniform(-1.0, 1.0, int(size))\n",
    "    b = np.random.uniform(-1.0, 1.0, int(size))\n",
    "\n",
    "    t = timeit(lambda: a * b, number=n) / n  # Do the benchmark\n",
    "    # We're only doing this a few times, so it doesn't matter that it's slow\n",
    "    times.append(t)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, sharex=True)  # NOTE: Example of multiple frame layout\n",
    "plt.sca(axes[0])\n",
    "plt.plot(sizes, times, color=\"k\")\n",
    "plt.ylabel(\"Time [s]\")\n",
    "\n",
    "plt.gca().set_yscale(\"log\")  # NOTE: Example of log-scale axes\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plt.plot(sizes, sizes / np.array(times), color=\"k\")\n",
    "plt.ylabel(\"Throughput [elems/s]\")\n",
    "\n",
    "# plt.gca().set_yscale(\"log\")\n",
    "plt.gca().set_xscale(\"log\")\n",
    "\n",
    "plt.xlabel(\"# Elems\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbf543a",
   "metadata": {},
   "source": [
    "##### cProfile & snakeviz\n",
    "\n",
    "When your script has more than a few lines in it, it may not be obvious where the pain points are. Profile your code to find out!\n",
    "\n",
    "**Note**: Run snakeviz here as example, since it doesn't embed well. Take bets on what are the slow parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df26d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "here = Path(os.path.abspath(\"\"))\n",
    "script = here / \"script_to_profile.py\"\n",
    "out = here / \"script_to_profile.prof\"\n",
    "\n",
    "# Instrument and profile the script\n",
    "subprocess.check_output([\"python\", \"-m\", \"cProfile\", \"-o\", str(out), str(script)])\n",
    "\n",
    "# Make a flame chart of the profile - this is how we'd do it programatically\n",
    "# subprocess.call([\"snakeviz\", str(out)])  # This doesn't return\n",
    "\n",
    "# ..Or in the terminal\n",
    "# snakeviz ./script_to_profile.prof\n",
    "\n",
    "# Or, supposedly, in a notebook, but I haven't got this to work\n",
    "# %load_ext snakeviz # Jupyter \"magic\" to load a plugin\n",
    "# %snakeviz \"./script_to_profile.prof\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e48633",
   "metadata": {},
   "source": [
    "##### Pyinstrument\n",
    "\n",
    "Pyinstrument combines a profiler and visualizer, and has a jupyter plugin as well as HTML/browser output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef0b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load jupyter plugin\n",
    "%load_ext pyinstrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacb66c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pyinstrument\n",
    "# Using the jupyter plugin here, but we could also run it\n",
    "# from the terminal like `pyinstrument -r html ./script_to_profile.prof`\n",
    "# NOTE: discuss difference in outputs between these two strategies\n",
    "# (terminal approach captures imports)\n",
    "\n",
    "from script_to_profile import do_stuff\n",
    "\n",
    "do_stuff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c06709",
   "metadata": {},
   "source": [
    "----\n",
    "#### Numerics\n",
    "\n",
    "`numpy` and `scipy` are the core offering of Python for engineering. They provide \n",
    "\n",
    "* Matrices and linear solvers\n",
    "* Array and matrix construction utilities (linspace, etc)\n",
    "* Interpolation\n",
    "* Signal filtering\n",
    "* Optimizers and rootfinders\n",
    "* ODE integrators\n",
    "\n",
    "... and so on.\n",
    "\n",
    "The `findiff` library also provides easy and reasonably-performant construction of finite-difference operators.\n",
    "\n",
    "Meanwhile, `sympy` provides symbolic math. For quasi-symbolic differentiation, see the section on automatic differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80076fff",
   "metadata": {},
   "source": [
    "##### Arrays, Matrices, and Tensors\n",
    "\n",
    "**Arrays** are a series of values stored together on disk.<br>\n",
    "Dense matrices are 2D arrays. Arrays can have more than 2 dimensions.<br>\n",
    "Tensors are any N-dimensional arrays on which tensor operations are performed.\n",
    "<br><br>\n",
    "Arrays' underlying storage can be either `C-contiguous` or `F-contiguous`. Only `C-contiguous` format is in common use and will be discussed here.\n",
    "* `C-contiguous`: Shape (20, 3) means you have 20 blocks of 3-element-long arrays. `arr[i, :]` refers to a solid block of memory.\n",
    "* `F-contiguous`: Shape (20, 3) means you have 3 blocks of 20-element-long arrays. `arr[:, i]` refers to a solid block of memory.\n",
    "\n",
    "This difference in storage is closely related to the difference between columnar and interleaved data; it represents the difference between storing points like `([x0, ..., xn], [y0, ..., yn])` (columnar) vs. `([x0, y0], ..., [xn, yn])` (interleaved).\n",
    "\n",
    "Slicing an array like `arr[:, i]` produces an **array view** that represents the result *conceptually* but may not be evaluated yet in order to avoid excess computation. Numpy arrays can be either a contiguous array or a discontiguous array view **without external indication**.\n",
    "\n",
    "Arrays can be reshaped at zero cost by simply changing the interpretation of the underlying dimensions. However, transposing a contiguous array requires a change in storage ordering, and will usually produce an array view that avoids the cost for as long as possible.\n",
    "\n",
    "**Sparse matrices** are a representation of only the nonzero entries in a matrix.<br>\n",
    "There are different formats of sparse matrix that have different advantages:\n",
    "\n",
    "* Triplet (aka COO): easy to construct, but bulky & slow to do math\n",
    "* Compressed Sparse Column (CSC): easy to decompose / prep solvers; good RHS of matrix-matrix product (fast column access)\n",
    "* Compressed Sparse Row (CSR): good LHS of matrix-matrix or matrix-vector product (fast row access)\n",
    "\n",
    "*Triplet format* is simply a series of `[(row, col, val), ...]` 3-element tuples, canonically *sorted by row then by column* within each row to facilitate conversion to other formats. It's the first thing that one would think of if asked to only store nonzero entries.\n",
    "\n",
    "*Compressed sparse matrix formats* with `nnz` nonzeroes and `n` rows or columns on the compressed axis store\n",
    "* (size nnz) Array of values \n",
    "* (size nnz) Array of uncompressed-axis indices \n",
    "* (size n)   Array of pointers to start of each row or column in the other arrays (whichever is compressed)\n",
    "\n",
    "The transpose of a compressed sparse matrix can be done at zero cost by simply changing the name from CSR to CSC or CSC to CSR, because the significance of the rows and columns can be swapped directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4d3d14",
   "metadata": {},
   "source": [
    "##### Numpy - Arrays and Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf1dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy provides methods for constructing and manipulating dense arrays and matrices.\n",
    "\n",
    "# Building monotonic series of values (for plotting, etc)\n",
    "a = np.linspace(0.0, 10.0, 25)\n",
    "b = np.arange(0.0, 10.0, 0.04)\n",
    "\n",
    "# Copy an array to prevent unexpected mutation\n",
    "a_sliced = a[::2].copy()\n",
    "\n",
    "# Make an array contiguous, copying only if necessary\n",
    "a_sliced_contig = np.ascontiguousarray(a[::2])  # This will copy\n",
    "a_contig = np.ascontiguousarray(a)  # This will return a reference\n",
    "\n",
    "# Building 2D meshes of values (for exploring a space, plotting, etc)\n",
    "X, Y = np.meshgrid(a, b, indexing=\"ij\")  # \"ij\" indexing makes the intuitive result\n",
    "\n",
    "# Generating random numbers\n",
    "mean, std = (0.0, 1.414)\n",
    "c = np.random.normal(loc=mean, scale=std, size=100)\n",
    "\n",
    "# Flattening and reshaping are compatible inverse operations\n",
    "# They are zero-cost - the underlying storage does not change, only the interpretation of it!\n",
    "c2d = c.reshape((10, 10))  # Follows C-ordering\n",
    "cflat = c2d.flatten()\n",
    "assert np.all(c == cflat)\n",
    "# 2D\n",
    "# [ 1, 0, 0 ]\n",
    "# [ 0, 1, 0 ]\n",
    "# [ 0, 0, 1 ]\n",
    "\n",
    "# Flattened (C-order) is a series of contiguous rows\n",
    "# [ 1, 0, 0 ][ 0, 1, 0 ][ 0, 0, 1 ]\n",
    "\n",
    "# Transpose\n",
    "c2dt = c2d.transpose()\n",
    "c2dt2 = c2d.T  # Shorthand\n",
    "\n",
    "# Extract diagonal\n",
    "cdiag = np.diag(c2d)  # Extract diagonal from matrix\n",
    "cdiag2 = np.diag(c)  # Create diagonal matrix\n",
    "\n",
    "# Create block-matrices\n",
    "eye = np.eye(*c2d.shape)\n",
    "# fmt: off\n",
    "cblock = np.block([\n",
    "    [eye, c2d], \n",
    "    [c2d, eye]\n",
    "])\n",
    "# fmt: on\n",
    "print(f\"Block-matrix shape: {cblock.shape}\")\n",
    "\n",
    "# Broadcasting operations\n",
    "c2d * np.ones((10, 1))  # Ok to do (10x10 * 10x1) along first axis\n",
    "c2d * np.ones((1, 10))  # Ok to do (10x10 * 1x10) along second axis\n",
    "c2d * np.ones((1, 1))  # Ok to do array-scalar with expanded dimensions\n",
    "c2d * 1.0  # Ok to do array-scalar with no dimensions\n",
    "\n",
    "c3d = c.reshape((4, 5, 5))\n",
    "c3dscaled = c3d * (0.5 * np.ones((4, 1, 1)))  # Multiply each 5x5 sub-array by 0.5\n",
    "c3dscaled = c3d * (0.5 * np.ones((4, 1, 5)))  # Broadcast along middle axis\n",
    "\n",
    "try:\n",
    "    c2d * c  # Not ok to do 10x10 * 100 - no matching axes\n",
    "except Exception as e:\n",
    "    print(f\"Noop: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bdb14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In general, numpy is significantly faster to do math operations than python, but only if you use it properly!\n",
    "\n",
    "npmul = lambda a, b: a * b  # Just use broadcasting!\n",
    "pymul_comprehension = lambda a, b: np.array([x * y for x, y in zip(a, b)])\n",
    "\n",
    "\n",
    "def pymul_index(a, b):\n",
    "    \"\"\"Don't do stuff like this\"\"\"\n",
    "    out = np.zeros((len(a),))  # Preallocating should help, right?\n",
    "    for i in range(len(a)):\n",
    "        out[i] = a[i] * b[i]\n",
    "\n",
    "    return np.array(out)\n",
    "\n",
    "\n",
    "def append_loop(a, b):\n",
    "    \"\"\"Don't do stuff like this\"\"\"\n",
    "    out = []\n",
    "    for i in range(len(a)):\n",
    "        out.append(a[i] * b[i])\n",
    "\n",
    "    return np.array(out)\n",
    "\n",
    "\n",
    "n = 100000\n",
    "t1 = timeit(lambda: pymul_comprehension(c, c), number=n) / n\n",
    "t1a = timeit(lambda: pymul_index(c, c), number=n) / n\n",
    "t2 = timeit(lambda: npmul(c, c), number=n) / n\n",
    "t3 = timeit(lambda: append_loop(c, c), number=n) / n\n",
    "\n",
    "print(f\"Python zip:   {t1:.1e} [s]\")\n",
    "print(f\"Python index: {t1a:.1e} [s]\")\n",
    "print(f\"Numpy:        {t2:.1e} [s]\")\n",
    "print(f\"Append loop:  {t3:.1e} [s]\")\n",
    "\n",
    "print(\"\\nTime ratios compared to numpy\")\n",
    "print(f\"Python zip:   {t1 / t2:.1f}\")\n",
    "print(f\"Python index: {t1a / t2:.1f}\")\n",
    "print(f\"Append loop:  {t3 / t2:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65348876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operating on discontiguous access patterns in numpy is only slightly slower.\n",
    "#\n",
    "# This distinction is much sharper in low-level compiled code, where it can make a difference of a factor of 10-100.\n",
    "# numpy doesn't mind that much because it's leaving a lot of potential performance on the table by using iterators for everything.\n",
    "\n",
    "cube = np.random.uniform(0.0, 1.0, 100**3).reshape((100, 100, 100))  # 20x20x20\n",
    "square = np.random.uniform(0.0, 1.0, 100**2).reshape((100, 100))  # 20x20\n",
    "\n",
    "contig = lambda a, b: a[2, :, :] * b  # Contiguous access pattern\n",
    "discontig = lambda a, b: a[:, 2, :] * b  # Scattered access pattern\n",
    "\n",
    "n = 100000\n",
    "t1 = timeit(lambda: np.sum(contig(cube, square)), number=n) / n\n",
    "t2 = timeit(lambda: np.sum(discontig(cube, square)), number=n) / n\n",
    "\n",
    "print(t2 / t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815cce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick warning about `numpy.vectorize`: it doesn't do anything for performance.\n",
    "# This does not \"vectorize\" anything!\n",
    "#\n",
    "# NOTE: Aside about vectorization as the combined effect of both sequential reads, SIMD, ILP, and cache efficiency\n",
    "from math import sinh\n",
    "\n",
    "vsinh = np.vectorize(sinh)\n",
    "\n",
    "n = 100000\n",
    "t1 = timeit(lambda: np.array([sinh(x) for x in c]), number=n) / n\n",
    "t2 = timeit(lambda: vsinh(c), number=n) / n\n",
    "\n",
    "print(f\"Python:            {t1:.2e} [s]\")\n",
    "print(f'Numpy \"vectorize\": {t2:.2e} [s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ad4489",
   "metadata": {},
   "source": [
    "##### Scipy - Variety Pack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bbc108",
   "metadata": {},
   "source": [
    "##### Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab9581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation in 1D, 2D, ND\n",
    "from scipy.interpolate import (\n",
    "    RegularGridInterpolator,\n",
    "    RectBivariateSpline,\n",
    "    interp1d,\n",
    "    pchip,\n",
    "    RBFInterpolator,\n",
    ")\n",
    "from interpn.multilinear_rectilinear import MultilinearRectilinear\n",
    "\n",
    "#    Grids\n",
    "xgrid = np.linspace(0.0, 5.0, 10)\n",
    "ygrid = np.linspace(-1.0, 1.0, 9)\n",
    "zgrid = np.linspace(2.0, 3.0, 7)\n",
    "#    Rectangular meshes\n",
    "xmesh, ymesh, zmesh = np.meshgrid(xgrid, ygrid, zgrid, indexing=\"ij\")\n",
    "#    Values at each mesh location\n",
    "u = np.sin((xmesh**2 + ymesh**2 + zmesh**2) ** 0.5)\n",
    "\n",
    "#    3D interpolator\n",
    "interp3d = RegularGridInterpolator((xgrid, ygrid, zgrid), u, method=\"linear\")\n",
    "interp3d_fast = MultilinearRectilinear.new(\n",
    "    [xgrid, ygrid, zgrid], u\n",
    ")  # Faster method for 3D+\n",
    "\n",
    "#    2D interpolators\n",
    "interp2d = RegularGridInterpolator((xgrid, ygrid), u[:, :, 0], method=\"cubic\")\n",
    "interp2d_fast = RectBivariateSpline(\n",
    "    xgrid, ygrid, u[:, :, 0]\n",
    ")  # Faster cubic method for 2D only\n",
    "\n",
    "#    1D interpolators\n",
    "interp1d_slow = interp1d(xgrid, u[:, 0, 0], kind=\"linear\")\n",
    "interp1d_fast = lambda x: np.interp(\n",
    "    x, xgrid, u[:, 0, 0]\n",
    ")  # Faster method for 1D linear only\n",
    "\n",
    "#    Specialty interpolators\n",
    "#        C1-continuous cubic w/ monotonicity constraint\n",
    "monotonic_hermite_cubic = pchip(xgrid, u[:, 0, 0])\n",
    "#        Radial basis function can handle point clouds.\n",
    "#\n",
    "#        A good rule of thumb is to use a linear kernel with a number of neighbors that reflects\n",
    "#        the vertices of a rectilinear unit cell in N dimensions (2 for linear, 4 for 2D, 8 for 3D, and so on)\n",
    "#        which recovers something similar to linear interpolation if the point cloud happens to land on a grid.\n",
    "point_cloud_x = np.random.uniform(-1.0, 1.0, 10)\n",
    "point_cloud_y = np.random.uniform(3.14, np.e, 10)\n",
    "point_cloud_u = np.sin((point_cloud_x**2 + point_cloud_y**2) ** 0.5)\n",
    "linear_radial_basis = RBFInterpolator(\n",
    "    np.array((point_cloud_x, point_cloud_y)).T,\n",
    "    point_cloud_u,\n",
    "    neighbors=4,\n",
    "    kernel=\"linear\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b301d518",
   "metadata": {},
   "source": [
    "##### Root-finding and minimization\n",
    "\n",
    "Root-finding is a popular method for solving arbitrary systems of equations by rephrasing\n",
    "\n",
    "$$ f(x) = g(x) $$\n",
    "\n",
    "as\n",
    "\n",
    "$$ f_{i}(x_{i}) - g_{i}(x_{i}) = err_{i} $$\n",
    "\n",
    "and solving to drive the error to zero. This is the underlying scheme behind nearly all methods for solving nonlinear systems, although the method for driving the error to zero varies widely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b47fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nonlinear root-finding and optimization\n",
    "from scipy.optimize import fsolve, minimize\n",
    "\n",
    "\n",
    "def f_colebrook(reynolds_number, roughness):\n",
    "    \"\"\"\n",
    "    Implicit Colebrook formula for friction factor. Once upon a time, this was the gold standard\n",
    "    but newer correlations like Bellos show better experimental agreement and are explicit\n",
    "\n",
    "    Arguments:\n",
    "        Re: Reynolds number, with hydraulic diameter as the length scale [units: dimensionless].\n",
    "        roughness: Pipe inside surface roughness scale height divided by pipe diameter [units: dimensionless].\n",
    "\n",
    "    Returns:\n",
    "        Darcy friction factor [units: dimensionless].\n",
    "    \"\"\"\n",
    "    re = reynolds_number\n",
    "    lhs = lambda f: f**-0.5\n",
    "    rhs = lambda f: -2 * np.log10((roughness / 3.7) + (2.51 / (re * f**0.5)))\n",
    "\n",
    "    # Root-finding method\n",
    "    err = lambda f: np.abs(lhs(f) - rhs(f))\n",
    "    f = fsolve(err, x0=[0.01], maxfev=1000)[0]  # Root-finder\n",
    "\n",
    "    # Error minimization method (we happen to know that the minimum of the squared error is zero)\n",
    "    # err2 = lambda f: (lhs(f) - rhs(f))**2  # Smooth error better for minimizer\n",
    "    # f = minimize(err2, x0=[0.01], tol=1e-8, method='Nelder-Mead').x[0]  # More general minimizer\n",
    "\n",
    "    return float(f)\n",
    "\n",
    "\n",
    "# Run the function to get the friction factor for a given Re and epsilon\n",
    "f_colebrook(reynolds_number=1e4, roughness=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b05fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watching the function evaluations of a rootfinder\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "\n",
    "def func(x: NDArray, point_log: list[NDArray] | None = None) -> NDArray:\n",
    "    \"\"\"Some convex function with logging\"\"\"\n",
    "    if point_log is not None:\n",
    "        point_log.append(x)  # Telemetry\n",
    "    out = np.zeros_like(x)\n",
    "    x0, x1 = x\n",
    "    out[0] = (x0 / 5 + 1) ** 4 * x1 / 5\n",
    "    out[1] = np.log((x1 / 5) ** 2 + 1.0) * (x0 / 5) ** 2\n",
    "    return out\n",
    "\n",
    "\n",
    "x0 = np.array([14.0, 9.0])\n",
    "point_log = [x0]\n",
    "res = fsolve(func, x0=x0, args=(point_log,))\n",
    "print(\"Solved point:\", res)\n",
    "print(\"Value at solved point:\", func(res))\n",
    "print(\"Function evaluations:\", len(point_log))\n",
    "\n",
    "xgrid = np.linspace(-15.0, 15.0, 40)\n",
    "ygrid = xgrid.copy()\n",
    "xmesh, ymesh = np.meshgrid(xgrid, ygrid, indexing=\"ij\")\n",
    "zmesh = np.zeros_like(xmesh).flatten()\n",
    "\n",
    "for i, (xp, yp) in enumerate(zip(xmesh.flatten(), ymesh.flatten())):\n",
    "    zmesh[i] = np.linalg.norm(func(np.array([xp, yp])))\n",
    "zmesh = zmesh.reshape(xmesh.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(zmesh.T, origin=\"lower\", extent=(-15, 15, -15, 15))\n",
    "plt.colorbar()\n",
    "plt.contour(xmesh, ymesh, zmesh, colors=\"k\")\n",
    "x, y = zip(*point_log)\n",
    "plt.plot(x, y, marker=\".\", color=\"w\")\n",
    "plt.scatter([x[-1]], [y[-1]], color=\"r\", zorder=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1870e4c9",
   "metadata": {},
   "source": [
    "##### Signal Processing\n",
    "\n",
    "* Signal processing combats nefarious organized noise that does not behave like statistical noise\n",
    "* Zero-phase forward/backward filtering is usually the right kind for postprocessing hardware performance data\n",
    "* Comparing filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc82aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal Processing: Zero-Phase Filtering\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt, dlti, dbode, dlsim\n",
    "\n",
    "# Make some noisy data\n",
    "x = np.linspace(0.0, 100.0, 10000)\n",
    "y_truth = np.sin(x)\n",
    "y_truth[600:] += 2.0  # Demonstrate response to step discontinuity\n",
    "y_meas = y_truth + np.random.normal(0.0, 0.2, len(x))  # Noisy signal\n",
    "\n",
    "# Filter\n",
    "cutoff = 0.01\n",
    "#   S-space polynomial coeffs for numerator and denominator\n",
    "filt1 = butter(1, cutoff)  # First-order filter for forward-backward filter\n",
    "filt2 = butter(2, cutoff)  # Second-order filter for forward filtering\n",
    "filt2_norm = butter(\n",
    "    2, cutoff, fs=1.0\n",
    ")  # Normalized to samplerate for bode plot purposes\n",
    "#   Run the filter forward (like a realtime deterministic filter)\n",
    "#   To compare to a forward-backward filter, use a 2nd-order filter for the forward-only version.\n",
    "y_filt = dlsim((*filt2, x[1] - x[0]), u=y_meas, t=x)[1]\n",
    "#   Run filter forward then backward, cancelling phase shift\n",
    "#   This is a nondeterministic filter (runs partially backward in time)\n",
    "#   suitable for post-test filtering. First order in each direction\n",
    "#   combines to make a second-order overall filter.\n",
    "y_filtfilt = filtfilt(*filt1, y_meas)\n",
    "\n",
    "# Frequency response\n",
    "filter_sys = dlti(*filt2_norm, dt=1.0)  # normalized to samplerate\n",
    "w, mag, phase = dbode(\n",
    "    filter_sys,\n",
    "    w=np.logspace(np.log10(cutoff / 10), np.log10(0.4), 1000) * 2.0 * np.pi,\n",
    ")\n",
    "f = w / (2.0 * np.pi)  # [Hz / samplerate] normalized freq\n",
    "\n",
    "# Mag\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=((7, 4)), sharex=True)\n",
    "ax1.set_xscale(\"log\")\n",
    "ax1.plot(f, mag, color=\"k\")\n",
    "ax1.set_ylabel(\"Gain [dB]\")\n",
    "ax1.axvline(cutoff, color=\"k\", alpha=1.0)\n",
    "ax1.grid(True)\n",
    "\n",
    "# Phase\n",
    "ax2.plot(f, phase, color=\"k\")\n",
    "ax2.set_ylabel(\"Phase [deg]\")\n",
    "ax2.set_xlabel(\"f / fs\")\n",
    "ax2.axhline(-90, color=\"k\", alpha=0.4)\n",
    "ax2.axvline(cutoff, color=\"k\", alpha=1.0)\n",
    "ax2.grid(True)\n",
    "plt.suptitle(\"Butterworth Order 2 - Forward Response\")\n",
    "\n",
    "# Time-domain response\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(x, y_meas, color=\"k\", alpha=0.3, label=\"Measured\")\n",
    "plt.plot(x, y_truth, linewidth=2, color=\"k\", label=\"Truth\")\n",
    "plt.plot(x, y_filt, color=\"b\", alpha=1.0, label=\"Fwd Filtered\")\n",
    "plt.plot(x, y_filtfilt, color=\"r\", alpha=0.6, label=\"Fwd-Bwd Filtered\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlabel(\"x\")\n",
    "\n",
    "# Time-domain zoom in\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(x[200:1000], y_meas[200:1000], color=\"k\", alpha=0.3, label=\"Measured\")\n",
    "plt.plot(x[200:1000], y_truth[200:1000], linewidth=2, color=\"k\", label=\"Truth\")\n",
    "plt.plot(x[200:1000], y_filt[200:1000], color=\"b\", alpha=1.0, label=\"Fwd Filtered\")\n",
    "plt.plot(\n",
    "    x[200:1000], y_filtfilt[200:1000], color=\"r\", alpha=0.6, label=\"Fwd-Bwd Filtered\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlabel(\"x\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2b168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal Processing: Comparing Filters\n",
    "# NOTE: Discuss phase behavior of FIR filters & phase behavior of both filters in non-causal form\n",
    "# NOTE: Discuss how number of FIR taps grows with decreasing cutoff ratio, but IIR filters stay the same\n",
    "import numpy as np\n",
    "from scipy.signal import butter, cheby1, savgol_coeffs, dlti, dbode, freqz\n",
    "\n",
    "\n",
    "def compare_filters(cutoff_ratio, ripple, poly_order, nsav, nmean):\n",
    "    #   S-space polynomial coeffs for numerator and denominator\n",
    "    iir_filters = [\n",
    "        (\n",
    "            f\"Butterworth Order {2 * (i + 1)}\",\n",
    "            butter(2 * (i + 1), Wn=cutoff_ratio, fs=1.0),\n",
    "        )\n",
    "        for i in [0, 2]\n",
    "    ]\n",
    "    iir_filters += [\n",
    "        (\n",
    "            f\"Chebyshev Order {2 * (i + 1)}\",\n",
    "            cheby1(2 * (i + 1), ripple, Wn=cutoff_ratio, fs=1.0),\n",
    "        )\n",
    "        for i in [0, 2]\n",
    "    ]\n",
    "    #   Filter taps (just a vector of floats to convolve with the signal)\n",
    "    fir_filters = []\n",
    "    fir_filters += [(f\"Sav-Gol Order 4 Size {nsav}\", savgol_coeffs(nsav, poly_order))]\n",
    "    fir_filters += [(f\"Sliding Mean Size {nmean}\", np.ones(nmean) / nmean)]\n",
    "\n",
    "    f = np.logspace(-3, np.log10(0.4), 1000)\n",
    "    w = f * (2.0 * np.pi)\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=((7, 4)), sharex=True)\n",
    "    ax1.set_xscale(\"log\")\n",
    "    ax1.axvline(cutoff_ratio, color=\"k\", alpha=1.0)\n",
    "    ax1.grid(True)\n",
    "    ax1.set_ylabel(\"Gain [dB]\")\n",
    "    ax1.set_ylim(bottom=-40)\n",
    "\n",
    "    ax2.set_xscale(\"log\")\n",
    "    ax2.axvline(cutoff_ratio, color=\"k\", alpha=1.0)\n",
    "    ax2.grid(True)\n",
    "    ax2.set_ylabel(\"Gain [dB]\")\n",
    "    ax2.set_ylim(bottom=-3)\n",
    "\n",
    "    ax3.set_ylabel(\"Phase [deg]\")\n",
    "    ax3.set_xlabel(\"f / fs\")\n",
    "    ax3.axhline(-90, color=\"k\", alpha=0.4)\n",
    "    ax3.axvline(cutoff_ratio, color=\"k\", alpha=1.0)\n",
    "    ax3.grid(True)\n",
    "\n",
    "    plt.suptitle(f\"Filter Comparison - Cutoff Ratio = {cutoff_ratio}\")\n",
    "\n",
    "    for name, fi in iir_filters:\n",
    "        filter_sys = dlti(*fi, dt=1.0)  # normalized to samplerate\n",
    "        w, mag, phase = dbode(filter_sys, w=w)\n",
    "        linestyle = \"-\" if \"butter\" in name.lower() else \"-.\"\n",
    "        ax1.plot(f, mag, linestyle=linestyle, label=name)\n",
    "        ax2.plot(f, mag, linestyle=linestyle, label=name)\n",
    "        ax3.plot(f, phase, linestyle=linestyle, label=name)\n",
    "\n",
    "    for name, fi in fir_filters:\n",
    "        _, h = freqz(fi, worN=w)\n",
    "        mag = 20.0 * np.log10(np.abs(h))\n",
    "        # phase = np.unwrap(np.angle(h, deg=True))  # No point examining this\n",
    "        ax1.plot(f, mag, linestyle=\"--\", label=name)\n",
    "        ax2.plot(f, mag, linestyle=\"--\", label=name)\n",
    "\n",
    "    ax1.legend(\n",
    "        ncol=2,\n",
    "        loc=\"upper left\",  # Anchor upper left corner of legend box at bbox_to_anchor\n",
    "        # Anchor here in normalized plot space relative to lower left corner\n",
    "        bbox_to_anchor=(1.0, 1.0),\n",
    "        edgecolor=\"black\",  # Color of legend frame\n",
    "        fancybox=False,  # No rounded edges\n",
    "        borderaxespad=0,  # Set padding between legend and plot frame\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c995a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At a cutoff ratio of 0.1, evaluation cost is fairly balanced between IIR and FIR\n",
    "\n",
    "cutoff_ratio = 0.1  # Target cutoff freq as a fraction of samplerate\n",
    "ripple = 0.1  # Allowed gain ripple before cutoff (in passband)\n",
    "poly_order = 4  # Polynomial order for sav-gol\n",
    "nsav = 17  # Number of Sav-Gol taps\n",
    "nmean = 5  # Number of sliding-mean taps\n",
    "\n",
    "compare_filters(cutoff_ratio, ripple, poly_order, nsav, nmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b665d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At a cutoff ratio of 0.01, evaluation cost is strongly in favor of IIR\n",
    "\n",
    "cutoff_ratio = 0.01  # Target cutoff freq as a fraction of samplerate\n",
    "ripple = 0.1  # Allowed gain ripple before cutoff (in passband)\n",
    "poly_order = 4  # Polynomial order for sav-gol\n",
    "nsav = 171  # Number of Sav-Gol taps\n",
    "nmean = 45  # Number of sliding-mean taps\n",
    "\n",
    "compare_filters(cutoff_ratio, ripple, poly_order, nsav, nmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a4e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reference for dB vs attenuation\n",
    "# NOTE: Discuss implications re: quality of filters\n",
    "\n",
    "attenuation = np.logspace(-6, 0, 1000)\n",
    "db = 20 * np.log10(attenuation)\n",
    "\n",
    "plt.plot(db, attenuation, color=\"k\")\n",
    "plt.xlabel(\"dB\")\n",
    "plt.ylabel(\"Attenuation\")\n",
    "plt.yscale(\"log\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9458b3",
   "metadata": {},
   "source": [
    "#### FinDiff & A Quick PDE Solver\n",
    "\n",
    "This example demonstrates setting up finite-difference differential operators and solving a 2D PDE (Grad-Shafranov axisymmetric flux solve), and compares the results to a hand-crafted solution.\n",
    "\n",
    "Implements the operator\n",
    "\n",
    "$$ \\Delta^{*} \\Psi \\equiv R \\frac{\\partial}{\\partial R} \\left( \\frac{1}{R} \\frac{\\partial \\Psi}{\\partial R} \\right)\n",
    "+ \\frac{\\partial^2 \\Psi}{\\partial Z^2}\n",
    "$$\n",
    "\n",
    "or, after a step of product rule,\n",
    "\n",
    "$$\n",
    "\\Delta^{*} \\Psi \\equiv \\frac{\\partial^2 \\Psi}{\\partial Z^2} + \\frac{\\partial^2 \\Psi}{\\partial R^2}\n",
    "                   - \\frac{1}{R} \\frac{\\partial \\Psi}{\\partial R}\n",
    "$$\n",
    "\n",
    "to solve\n",
    "\n",
    "$$\n",
    "\\Delta^{*} \\Psi = - \\mu _{0} * (2 \\pi  R) * J_{tor}\n",
    "$$\n",
    "\n",
    "FinDiff develops the finite difference stencils either using stored templates (for regular grids) or, for irregular grids, by symbolically inverting a Vandermonde matrix to resolve the coefficients of a minimum-order polynomial for each footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e392531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "import findiff\n",
    "# from findiff.grids import Grid, NonEquidistantAxis  # For irregular grids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f198d9",
   "metadata": {},
   "source": [
    "##### Set up the grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d98b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up grids\n",
    "rgrid = np.linspace(0.01, 5.0, 100)  # [m]\n",
    "zgrid = np.linspace(-4.0, 4.0, int(8.0 / 0.05))  # [m]\n",
    "rmesh, zmesh = np.meshgrid(rgrid, zgrid, indexing=\"ij\")  # [m]\n",
    "\n",
    "dr = rgrid[1] - rgrid[0]  # [m]\n",
    "dz = zgrid[1] - zgrid[0]  # [m]\n",
    "\n",
    "nr, nz = len(rgrid), len(zgrid)\n",
    "\n",
    "# For irregular grids:\n",
    "# dr = np.diff(rgrid)\n",
    "# dr = np.diff(rgrid, prepend=rgrid[0] - dr[0])\n",
    "# dz = np.diff(zgrid)\n",
    "# dz = np.diff(zgrid, prepend=zgrid[0] - dz[0])\n",
    "\n",
    "# drmesh = np.tile(dr, nz).reshape(rmesh.shape)\n",
    "# dzmesh = np.tile(dz, nr).reshape(rmesh.shape)\n",
    "\n",
    "extent = (np.min(rgrid), np.max(rgrid), np.min(zgrid), np.max(zgrid))  # [m]\n",
    "\n",
    "target_shape = rmesh.shape\n",
    "\n",
    "# Build abstract differential operators\n",
    "# rax = NonEquidistantAxis(0, rgrid)  # For irregular grids\n",
    "# zax = NonEquidistantAxis(1, zgrid)\n",
    "grid = {0: dr, 1: dz}\n",
    "\n",
    "ddr_op = findiff.Diff(0, acc=4)  # [1/m]\n",
    "ddr_op.set_grid(grid)\n",
    "ddz_op = findiff.Diff(1, acc=4)  # [1/m]\n",
    "ddz_op.set_grid(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed4ad9a",
   "metadata": {},
   "source": [
    "##### Build differential operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494859d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realize differential operators & build LHS\n",
    "ddr = ddr_op.matrix(target_shape)  # [1/m]\n",
    "ddr2 = (ddr_op**2).matrix(target_shape)  # [1/m^2]\n",
    "ddz2 = (ddz_op**2).matrix(target_shape)  # [1/m^2]\n",
    "\n",
    "# R-factors as diagonal matrices\n",
    "r = sparse.diags_array(rmesh.flatten())  # [m] r as row scaling\n",
    "rinv = sparse.diags_array(1 / rmesh.flatten())  # [1/m] 1/r as row scaling\n",
    "\n",
    "# Full delta-star operator\n",
    "# delta_star = r @ ddr @ rinv @ ddr + ddz2  # Form 1\n",
    "delta_star = ddr2 + ddz2 - rinv @ ddr  # [1/m^2] Form 2\n",
    "delta_star = delta_star.tocsr()  # CSR for setting BCs\n",
    "\n",
    "# 'spy' can show the sparsity pattern of a large matrix without\n",
    "# actualizing the whole thing\n",
    "plt.spy(delta_star, color=\"k\")\n",
    "plt.title(r\"$\\Delta^{*}$ Operator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952479b3",
   "metadata": {},
   "source": [
    "##### Build right-hand-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e448d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the RHS\n",
    "# -2.0 * pi * mu_0 * R * jtor\n",
    "from scipy.constants import mu_0\n",
    "\n",
    "# Example current density distribution\n",
    "rmid, zmid = np.mean(rgrid), np.mean(zgrid)  # [m]\n",
    "radius = 0.5  # [m]\n",
    "circle = lambda r, z: np.where((r - rmid) ** 2 + (z - zmid) ** 2 <= radius**2, 1.0, 0.0)\n",
    "jtor = circle(rmesh, zmesh)  # [A/m^2] toroidal current density\n",
    "\n",
    "# RHS given current density distribution\n",
    "rhs = -2.0 * np.pi * mu_0 * rmesh * jtor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bbae4d",
   "metadata": {},
   "source": [
    "##### Set BCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab24f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set BCs in LHS\n",
    "# This enforces that each point on the boundary of the solution will be held to the exact value found on the boundary in the RHS\n",
    "# which allows us to send through a solution calculated using a filament formula that is the Green's Function for this system.\n",
    "#\n",
    "# This practice of setting the boundary values to a valid solution before the solve allows us to solve over a finite domain\n",
    "# instead of needing to integrate to infinity to model the free boundary of the domain.\n",
    "\n",
    "#    Get boundary indices\n",
    "rows, cols = np.meshgrid(range(nr), range(nz), indexing=\"ij\")\n",
    "flats = np.array(range(nr * nz)).reshape(target_shape)\n",
    "\n",
    "brows, bcols = [], []\n",
    "bflats = []\n",
    "for s in [(0, ...), (-1, ...), (..., 0), (..., -1)]:\n",
    "    brows.extend(rows[s])\n",
    "    bcols.extend(cols[s])\n",
    "    bflats.extend(flats[s])\n",
    "\n",
    "boundary_inds = (brows, bcols)\n",
    "\n",
    "#    Set boundary rows to 1\n",
    "eye = sparse.eye(*delta_star.shape, format=\"csr\")\n",
    "for i in bflats:\n",
    "    delta_star[i, :] = eye[i, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad8eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set BCs in RHS\n",
    "from cfsem import flux_circular_filament\n",
    "\n",
    "inds = np.where(jtor.flatten() != 0.0)  # Where there is current\n",
    "\n",
    "# Green's function method for BC\n",
    "jtor[boundary_inds] = flux_circular_filament(\n",
    "    jtor.flatten()[inds],\n",
    "    rmesh.flatten()[inds],\n",
    "    zmesh.flatten()[inds],\n",
    "    rmesh[boundary_inds],\n",
    "    zmesh[boundary_inds],\n",
    ")  # [Wb] we're mixing units within this array because some entries are pre-solve forcing terms, and some are post-solve BCs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca629c9d",
   "metadata": {},
   "source": [
    "##### Solve the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c3d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve\n",
    "solver = sparse.linalg.factorized(delta_star.tocsc())\n",
    "psi = solver(rhs.flatten()).reshape(target_shape)  # [Wb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a104f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "plt.sca(axes[0])\n",
    "plt.imshow(jtor.T, origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "plt.colorbar()\n",
    "plt.title(\"jtor [A/m^2]\")\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plt.imshow(psi.T, origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "plt.gca().contour(psi.T, levels=6, colors=\"k\", linewidths=1, extent=extent)\n",
    "plt.colorbar()\n",
    "plt.title(\"psi [Wb]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af12ee83",
   "metadata": {},
   "source": [
    "##### Compare to reference implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9791f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cfsem import gs_operator_order4\n",
    "\n",
    "# Get operator with BCs already set\n",
    "val, row, col = gs_operator_order4(rgrid, zgrid)\n",
    "delta_star_cfsem = sparse.coo_matrix((val, (row, col))).tocsc()\n",
    "\n",
    "# Solve\n",
    "solver_cfsem = sparse.linalg.factorized(delta_star_cfsem)\n",
    "psi_cfsem = solver_cfsem(rhs.flatten()).reshape(target_shape)  # [Wb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab01cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "plt.sca(axes[0])\n",
    "plt.imshow(jtor.T, origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "plt.colorbar()\n",
    "plt.title(\"jtor [A/m^2]\")\n",
    "\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plt.imshow(psi_cfsem.T, origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "plt.gca().contour(psi_cfsem.T, levels=6, colors=\"k\", linewidths=1, extent=extent)\n",
    "plt.colorbar()\n",
    "plt.title(\"psi (cfsem) [Wb]\")\n",
    "\n",
    "err = psi.T - psi_cfsem.T\n",
    "plt.sca(axes[2])\n",
    "plt.imshow(err, origin=\"lower\", extent=extent, aspect=\"equal\")\n",
    "plt.colorbar()\n",
    "plt.title(\"psi err [Wb]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ded90d",
   "metadata": {},
   "source": [
    "----\n",
    "#### Plotting\n",
    "\n",
    "* Matplotlib is the most popular & mirrors matlab's plotting API\n",
    "  * Good for publications, posters, etc\n",
    "  * Only interactive while program is running\n",
    "* Seaborn provides better styling for matlab\n",
    "* Plotly provides HTML plots\n",
    "  * Good for persistent documentation that retain interactivity after program exits\n",
    "  * Also able to generate static plots when needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0282c4",
   "metadata": {},
   "source": [
    "##### Styling w/ Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9435d386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"paper\", font_scale=1.4)\n",
    "# NOTE: Try other styles (white, whitegrid, ticks, dark, darkgrid)\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_palette(\"cubehelix\")\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "plt.title(\"Basic paper-style plots\")\n",
    "plt.plot(x, y_filtfilt, linewidth=1.5)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.title(\"Too smooth? Turn off antialiasing\")\n",
    "plt.plot(x, y_filtfilt, linewidth=1.0, antialiased=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c72060",
   "metadata": {},
   "source": [
    "##### Vector Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252895e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display SVG in a notebook for crisper plots\n",
    "# %config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# Save figures as SVG or EPS (vector graphics formats)\n",
    "# to keep that crispness forever\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(x, y_filtfilt, linewidth=1.5)\n",
    "\n",
    "svg_path = static_dir / \"paper_style.svg\"\n",
    "plt.savefig(svg_path)\n",
    "\n",
    "plt.title(\"Use SVG for crisp lines at any scale\\n(uncomment the %config line)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b892f2",
   "metadata": {},
   "source": [
    "##### Example: Fill-Between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376b7bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "y0 = y_filt.flatten()[:1000]\n",
    "y1 = y_filtfilt.flatten()[:1000]\n",
    "plt.plot(x[:1000], y0, color=\"k\", linewidth=1.0)\n",
    "plt.plot(x[:1000], y1, color=\"k\", linewidth=1.0)\n",
    "plt.fill_between(x[:1000], y0, y1, color=\"k\", alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20a7184",
   "metadata": {},
   "source": [
    "##### Plotly\n",
    "\n",
    "Plotly generates interactive HTML plots, which are typically not the kind used for a publication, but preserves pan, zoom, and mouse-hover inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d80082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px  # Shortcut API\n",
    "from plotly import graph_objects as go  # Detailed API\n",
    "\n",
    "# \"express\" shorthand API\n",
    "px.line(x=x[:1000], y=y0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6b743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed API can be massaged to produce matplotlib-like output\n",
    "fig = go.Figure(data=[go.Scatter(x=x, y=y_filtfilt, line={\"color\": \"black\"})])\n",
    "fig.update_layout(plot_bgcolor=\"white\")\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    # gridcolor='lightgrey'\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    # gridcolor='lightgrey'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly can also export SVG output\n",
    "# This requires the additional \"kaleido\" dep that is not installed by default\n",
    "fig.write_image(static_dir / \"paper_style_plotly.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94226a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D scatter plots - Plotly is much better for this than matplotlib\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(\n",
    "            x=x[:1000], y=y0, z=y1, line={\"color\": \"black\"}, marker={\"size\": 2}\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d40f455",
   "metadata": {},
   "source": [
    "##### Accessibility\n",
    "\n",
    "Using distinct combinations of markers and colors that have distinct intensity can be helpful for the ~4% of the population that has some kind of colorblindness. It's also helpful for everyone else.\n",
    "\n",
    "To do this,\n",
    "\n",
    "* Use an intensity-mapped color palette like \"cubehelix\" or \"colorblind\"\n",
    "* Use a cycle of markers that are distinct independent of color\n",
    "* Make the color and marker cycles' length not an integer multiple of each other\n",
    "  * Or make a cycle over the cartesian product of both like `cycle(product(colors, markers))`\n",
    "  * Offset cycle makes a better pattern\n",
    "* Choose a number of markers you'd like to see per trace (usually around 5-10) and only plot those instead of every marker\n",
    "* Offset sequential markers from each other so that they avoid overlaps when possible\n",
    "\n",
    "There are also some more helpful habits that can improve the usability of plots in general\n",
    "* Use a font size that is readable from the same distance where the plot data is readable - shouldn't have to squint\n",
    "* Place the legend outside the plot so that people can see what is going on in both the legend and the plot\n",
    "* Use markers that can be referred to easily by name\n",
    "  * This way, discussion can happen without struggling through the \"no the other one that's kind of a rotated square - not that one, that's a diamond - no, the filled one, not the outline - ...\"\n",
    "  * Letters of the alphabet work well for this, as long as you only take one from each confusing group like `I / J / L`, `Q / O / D`, and `M / N / W / V` that can be difficult to distinguish in a busy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d826f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib accessibility formatting\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "colors = cycle(sns.cubehelix_palette(n_colors=10))\n",
    "# colors = cycle(sns.color_palette(\"colorblind\", n_colors=7))  # Another good option\n",
    "markers = cycle([\"$A$\", \"$B$\", \"$C$\", \"$D$\", \"$E$\", \"$F$\", \"$G$\", \"$H$\", \"$K$\"])\n",
    "\n",
    "nmarkers = 6  # Target number of markers in-frame for each trace\n",
    "n = len(x)  # Total number of data points\n",
    "nskip = int(n // nmarkers)  # Number of indices to skip between markers\n",
    "noffs = max(int(nskip / 10), 1)  # Amount to offset the start of each series of markers\n",
    "\n",
    "plt.figure()\n",
    "for i in range(20):\n",
    "    # Get the next marker/color combo\n",
    "    c = next(colors)\n",
    "    m = next(markers)\n",
    "\n",
    "    # Draw the line\n",
    "    yi = np.sin(i * x / 200)\n",
    "    plt.plot(x, yi, color=c, linewidth=2)\n",
    "\n",
    "    # Mark every nth data point, starting at an offset to avoid overlapping markers\n",
    "    marker_start = (i * noffs) % nskip\n",
    "    plt.scatter(\n",
    "        x[marker_start::nskip], yi[marker_start::nskip], color=c, marker=m, label=f\"{i}\"\n",
    "    )\n",
    "\n",
    "plt.legend(\n",
    "    ncol=3,\n",
    "    loc=\"upper left\",  # Anchor upper left corner of legend box at bbox_to_anchor\n",
    "    bbox_to_anchor=(\n",
    "        1.0,\n",
    "        1.0,\n",
    "    ),  # Anchor here in normalized plot space relative to lower left corner\n",
    "    edgecolor=\"black\",  # Color of legend frame\n",
    "    fancybox=False,  # No rounded edges\n",
    "    borderaxespad=0,  # Set padding between legend and plot frame\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bf9177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly accessibility formatting\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "colors = cycle(sns.cubehelix_palette(n_colors=10).as_hex())\n",
    "# colors = cycle(sns.color_palette(\"colorblind\", n_colors=7))  # Another good option\n",
    "markers = cycle(\n",
    "    [\n",
    "        \"circle\",\n",
    "        \"square\",\n",
    "        \"diamond\",\n",
    "        \"cross\",\n",
    "        \"triangle-up\",\n",
    "        \"triangle-down\",\n",
    "        \"triangle-left\",\n",
    "        \"triangle-right\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "nmarkers = 6  # Target number of markers in-frame for each trace\n",
    "n = len(x)  # Total number of data points\n",
    "nskip = int(n // nmarkers)  # Number of indices to skip between markers\n",
    "noffs = max(int(nskip / 10), 1)  # Amount to offset the start of each series of markers\n",
    "\n",
    "data = []\n",
    "for i in range(20):\n",
    "    # Get the next marker/color combo\n",
    "    c = next(colors)\n",
    "    m = next(markers)\n",
    "\n",
    "    # Draw the line\n",
    "    yi = np.sin(i * x / 200)\n",
    "    data.append(\n",
    "        go.Scatter(x=x, y=yi, line={\"color\": c}, mode=\"lines\", showlegend=False)\n",
    "    )\n",
    "\n",
    "    # Mark every nth data point, starting at an offset to avoid overlapping markers\n",
    "    marker_start = (i * noffs) % nskip\n",
    "    data.append(\n",
    "        go.Scatter(\n",
    "            x=x[marker_start::nskip],\n",
    "            y=yi[marker_start::nskip],\n",
    "            marker={\"color\": c, \"symbol\": m, \"size\": 8},\n",
    "            mode=\"markers\",\n",
    "            name=f\"{i}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "fig.update_layout(\n",
    "    plot_bgcolor=\"white\",\n",
    "    # Horizontal legend above plot will wrap into multiple lines,\n",
    "    # but vertical legend to the side will not wrap to multiple columns\n",
    "    legend=dict(\n",
    "        entrywidth=0.1,\n",
    "        entrywidthmode=\"fraction\",\n",
    "        orientation=\"h\",\n",
    "        y=1.2,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "    ),\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    # gridcolor='lightgrey'\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    # gridcolor='lightgrey'\n",
    ")\n",
    "fig.update_xaxes(range=[np.min(x), np.max(x)])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d15fc",
   "metadata": {},
   "source": [
    "##### Example - Moody Chart\n",
    "\n",
    "A common reference chart in fluid mechanics is the Moody chart, which shows pipe flow friction factor (used to calculate how much pressure is required to drive a given flowrate) as a function of Reynold's Number ($Re = \\frac{\\rho * v * D_h}{\\mu}$) and relative roughness ($\\epsilon = \\frac{\\text{surface roughness}}{D_h}$).\n",
    "\n",
    "There are a variety of methods for calculating the friction factor, and they produce different results for a given $Re$ and $\\epsilon$. There are also a wide range of methods for calculating what constitutes \"surface roughness\" since surface profiles come in many forms that affect flow differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ff611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "re = np.logspace(\n",
    "    2.8, 8, 300\n",
    ")  # [dimensionless] Reynold's Number w.r.t. hydraulic diameter\n",
    "roughness = [\n",
    "    1e-5,\n",
    "    1e-4,\n",
    "    1e-3,\n",
    "    1e-2,\n",
    "    0.05,\n",
    "    0.1,\n",
    "]  # [dimensionless] relative roughness w.r.t. hydraulic diameter\n",
    "\n",
    "TURBULENT_CUTOFF = 4000.0  # [dimensionless] Rule-of-thumb Re where a pipe flow should be fully turbulent\n",
    "TRANSITION_CUTOFF = (\n",
    "    2300.0  # [dimensionless] Rule-of-thumb Re where laminar-turbulent transition starts\n",
    ")\n",
    "\n",
    "\n",
    "# First method is implicit -> expensive and only covers turbulent region\n",
    "def f_with_colebrook(re: NDArray, roughness: float) -> NDArray:\n",
    "    \"\"\"\n",
    "    A friction factor calculation using the implicit Colebrook eqn for the turbulent regime\n",
    "    and a linear weighted average blending to the analytic laminar calc through the transition region.\n",
    "    \"\"\"\n",
    "    out = np.array([f_colebrook(x, roughness) for x in re])\n",
    "    out_lam = 64.0 / re  # Laminar friction factor is a very simple formula\n",
    "\n",
    "    # Find regions\n",
    "    # turb = np.where(re > TURBULENT_CUTOFF)\n",
    "    lam = np.where(re < TRANSITION_CUTOFF)\n",
    "    transitional = np.where((re >= TRANSITION_CUTOFF) & (re <= TURBULENT_CUTOFF))\n",
    "\n",
    "    # Make blended transition region\n",
    "    weight = (re[transitional] - TRANSITION_CUTOFF) / (\n",
    "        TURBULENT_CUTOFF - TRANSITION_CUTOFF\n",
    "    )\n",
    "    out[transitional] = (\n",
    "        weight * out[transitional] + (1.0 - weight) * out_lam[transitional]\n",
    "    )\n",
    "    # Make laminar region\n",
    "    out[lam] = out_lam[lam]\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Second method is explicit and covers full range from laminar to fully turbulent\n",
    "def f_bellos(re: NDArray, roughness: float):\n",
    "    \"\"\"\n",
    "    An explicit correlation of Darcy friction factor for pipe flow\n",
    "    with Reynolds number and surface roughness.\n",
    "\n",
    "    Arguments:\n",
    "        re: Reynolds number, with hydraulic diameter as the length scale [units: dimensionless].\n",
    "        roughness: Pipe inside surface roughness scale height divided by pipe diameter [units: dimensionless].\n",
    "\n",
    "    Returns:\n",
    "        Darcy friction factor [units: dimensionless].\n",
    "\n",
    "    References:\n",
    "        [1] Vasilis Bellos, Ioannis Nalbantis, and George Tsakiris, \"Friction Modeling of Flood Flow Simulations,\"\n",
    "            Journal of Hydraulic Engineering, Dec 2018.\n",
    "            https://doi.org/10.1061%2F%28asce%29hy.1943-7900.0001540\n",
    "        [2] Vasilis Bellos, Ioannis Nalbantis, and George Tsakiris, \"Erratum for 'Friction Modeling of Flood Flow Simulations',\"\n",
    "            Journal of Hydraulic Engineering, Oct 2020.\n",
    "    \"\"\"\n",
    "    a = 1 / (1 + (re / 2712.0) ** 8.4)\n",
    "    b = 1 / (1 + (re * roughness / 150.0) ** 1.8)\n",
    "    f = (\n",
    "        (64 / re) ** a\n",
    "        * (0.75 * np.log(re / 5.37)) ** (2 * (a - 1) * b)\n",
    "        * (0.88 * np.log(3.41 / roughness)) ** (2 * (a - 1) * (1 - b))\n",
    "    )\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd18af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot Moody charts of both calc methods\n",
    "for name, func in [\n",
    "    (\"Implicit Colebrook\", f_with_colebrook),\n",
    "    (\"Explicit Bellos\", f_bellos),\n",
    "]:\n",
    "    data = []\n",
    "    for e in roughness:\n",
    "        # Draw the line\n",
    "        yi = func(re, e)\n",
    "        data.append(\n",
    "            go.Scatter(\n",
    "                x=re, y=yi, line={\"color\": \"black\"}, mode=\"lines\", showlegend=False\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Mark the end of each trace\n",
    "        data.append(\n",
    "            go.Scatter(\n",
    "                x=[re[-1]],\n",
    "                y=[yi[-1]],\n",
    "                mode=\"text\",\n",
    "                text=f\"D/ε={1 / e:.0f}\",\n",
    "                textposition=\"middle right\",\n",
    "                showlegend=False,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig = go.Figure(data=data)\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor=\"white\",\n",
    "        title=name,\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        mirror=True,\n",
    "        ticks=\"outside\",\n",
    "        showline=True,\n",
    "        linecolor=\"black\",\n",
    "        # gridcolor='lightgrey'\n",
    "        type=\"log\",\n",
    "        title=\"Re [dimensionless]\",\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        mirror=True,\n",
    "        ticks=\"outside\",\n",
    "        showline=True,\n",
    "        linecolor=\"black\",\n",
    "        # gridcolor='lightgrey'\n",
    "        title=\"friction factor [dimensionless]\",\n",
    "    )\n",
    "    fig.update_xaxes(range=[np.log10(np.min(re)), np.log10(np.max(re) + 3e8)])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed0ea19",
   "metadata": {},
   "source": [
    "----\n",
    "#### Autodiff & Optimization Frameworks\n",
    "\n",
    "* [Casadi](https://web.casadi.org/) - excellent for **sparse systems** (typical for controls)\n",
    "  * **First-class support for solvers and constraints**\n",
    "  * Uses either interior point or SQP nonlinear solver under the hood w/ excellent method for Jacobian traversal\n",
    "  * Significantly enhanced by using convenience methods from [aerosandbox](https://github.com/peterdsharpe/AeroSandbox)\n",
    "  * Can do codegen in C for simple systems (intended to support embedded control systems)\n",
    "  * Medium software build quality - could use better type hinting and such\n",
    "  * Fantastic support for **arbitrary nonlinear constraints** on any part of the expression (inputs, intermediate states, or outputs)\n",
    "    * Incredibly powerful tool for constrained design optimization or simulation!\n",
    "* [Jax](https://docs.jax.dev/en/latest/quickstart.html) - excellent for **dense systems** (typical for matrix-free PDE solvers and ML)\n",
    "  * Essentially **no native support for constraints or optimization - only differentiation**\n",
    "    * Can be used as a backend for functions in Casadi! Casadi accepts plugins from anywhere - this gives a quick way to bring Jax capabilities into a proper solver framework\n",
    "  * Provides a JIT (just-in-time compiler) in addition to differentiation capability\n",
    "  * Not clever about Jacobian traversal - always either forward or backward (this is good enough for many things)\n",
    "  * Excellent software build quality (it's a google product)\n",
    "* [CVXPY](https://www.cvxpy.org/) - for large or discrete, sparse or dense, **strictly convex systems** (linear, and geometric programs) or systems having a strictly convex linear relaxation (mixed-integer linear)\n",
    "  * **First-class support for solvers and constraints**\n",
    "  * Can solve **enormous systems** with **40,000+ variables**\n",
    "  * Primarily for **disciplined convex systems** - not general nonlinear capability like Casadi\n",
    "  * Mixed-integer programs include operations planning algorithms (for example, scheduling shifts or machine time, packing, shipping/delivery, etc)\n",
    "* [tensorflow](https://www.tensorflow.org/) and [scikit-learn](https://scikit-learn.org/stable/) - machine learning only\n",
    "  * Honorable mention because they do some autodiff activities under the hood, but aren't as useful for more general problem-solving\n",
    "  \n",
    "\n",
    "A quick primer on what these do -\n",
    "\n",
    "##### The goal\n",
    "\n",
    "**Solve systems of nonlinear equations**, usually phrased as an **optimization** or **root-finding** problem.\n",
    "\n",
    "This class of problem includes \n",
    "\n",
    "* Engineering simulations (ODE & DAE integrators, algebraic equilibrium problems, etc)\n",
    "* Design optimization\n",
    "* Optimal control\n",
    "* Machine learning & curvefitting\n",
    "\n",
    "and anything else that you can phrase as a system of equations.\n",
    "\n",
    "##### Under the hood\n",
    "\n",
    "The first and most essential function of an autodiff system is to **calculate the gradient of a function or the Jacobian matrix of a system**, which is the matrix of first derivatives - the  sensitivities of all of the outputs to all of the inputs.\n",
    "\n",
    "Given some vector function $\\mathbf{y} = f(\\mathbf{x})$, the Jacobian is\n",
    "\n",
    "$J(\\mathbf{x})\n",
    "=\\begin{bmatrix}\n",
    "\\displaystyle\\frac{\\partial y_{1}}{\\partial x_{1}} & \\displaystyle\\frac{\\partial y_{1}}{\\partial x_{2}} & \\cdots & \\displaystyle\\frac{\\partial y_{1}}{\\partial x_{n}}\\\\[1em]\n",
    "\\displaystyle\\frac{\\partial y_{2}}{\\partial x_{1}} & \\displaystyle\\frac{\\partial y_{2}}{\\partial x_{2}} & \\cdots & \\displaystyle\\frac{\\partial y_{2}}{\\partial x_{n}}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\\displaystyle\\frac{\\partial y_{m}}{\\partial x_{1}} & \\displaystyle\\frac{\\partial y_{m}}{\\partial x_{2}} & \\cdots & \\displaystyle\\frac{\\partial y_{m}}{\\partial x_{n}}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "The gradient of each individual output forms one column of the Jacobian.\n",
    "\n",
    "The Jacobian can be built either \"forward\" (on column at a time) by calculating forward sensitivites to each input, or \"backward\" (one row at a time) by accumulating the sensitivity of each output back to the inputs using repeated application of the chain rule.\n",
    "* Forward differentiation: Low-memory, good for cases with **few inputs** and **many outputs** - columns of J are larger than rows\n",
    "* Reverse differentiation: High-memory, good for cases with **many inputs** and **few outputs** - rows of J are larger than columns\n",
    "\n",
    "For a large function, the full Jacobian can be calculated **partly in forward mode** and **partly in reverse mode**. Choosing the best possible mix of forward- and reverse-mode accumulation is called the **Jacobian Traversal Problem** and is known to be **NP-hard** - it is unreasonable to look for an optimal solution, but there are some good heuristics.\n",
    "\n",
    "Autodiff frameworks allow composing the calculation of gradients and jacobians, which allows calculating the **Hessian matrix** - the matrix of second derivatives (the Jacobian of the gradient). Because this is a very expensive 3D result for functions with multiple outputs, it is usually applied to a **cost function** that rolls many contributions up into a **single output** so that the resulting Hessian matrix is 2D.\n",
    "\n",
    "$H(\\mathbf{x}) = J(\\nabla f(\\mathbf{x})) =\n",
    "\\begin{bmatrix}\n",
    "\\displaystyle\n",
    "\\frac{\\partial^2 f}{\\partial x_1^2}\n",
    "& \n",
    "\\displaystyle\n",
    "\\frac{\\partial^2 f}{\\partial x_1\\,\\partial x_2}\n",
    "& \n",
    "\\cdots \n",
    "& \n",
    "\\displaystyle\n",
    "\\frac{\\partial^2 f}{\\partial x_1\\,\\partial x_n}\n",
    "\\\\[1em]\n",
    "\\displaystyle\n",
    "\\frac{\\partial^2 f}{\\partial x_2\\,\\partial x_1}\n",
    "& \n",
    "\\displaystyle\n",
    "\\frac{\\partial^2 f}{\\partial x_2^2}\n",
    "& \n",
    "\\cdots\n",
    "& \n",
    "\\displaystyle\n",
    "\\frac{\\partial^2 f}{\\partial x_2\\,\\partial x_n}\n",
    "\\\\[0.75em]\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\[0.75em]\n",
    "\\displaystyle\n",
    "\\frac{\\partial^2 f}{\\partial x_n\\,\\partial x_1}\n",
    "&\n",
    "\\displaystyle\n",
    "\\frac{\\partial^2 f}{\\partial x_n\\,\\partial x_2}\n",
    "&\n",
    "\\cdots\n",
    "&\n",
    "\\displaystyle\n",
    "\\frac{\\partial^2 f}{\\partial x_n^2}\n",
    "\\end{bmatrix}.\n",
    "$\n",
    "\n",
    "##### Further Reading\n",
    "\n",
    "* [1] M. Saroufim, “Automatic Differentiation Step by Step,” Medium. Accessed: Jun. 06, 2021. [Online]. Available: https://marksaroufim.medium.com/automatic-differentiation-step-by-step-24240f97a6e6\n",
    "\n",
    "* [2] J. Hückelheim, H. Menon, W. Moses, B. Christianson, P. Hovland, and L. Hascoët, “Understanding Automatic Differentiation Pitfalls,” May 12, 2023, arXiv: arXiv:2305.07546. doi: 10.48550/arXiv.2305.07546.\n",
    "\n",
    "* [3] U. Naumann, “Optimal Jacobian accumulation is NP-complete,” Math. Program., vol. 112, no. 2, pp. 427–441, Nov. 2007, doi: 10.1007/s10107-006-0042-z.\n",
    "\n",
    "* More about expression graphs: https://docs.sympy.org/latest/tutorials/intro-tutorial/manipulation.html\n",
    "\n",
    "**... along with the source code of any of the open-source frameworks!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a871ed",
   "metadata": {},
   "source": [
    "##### Example - Optimal Charging of an Inductor w/ Series Varistor & Parallel Resistor\n",
    "\n",
    "...subject to limits on terminal voltage, current, and dissipated power in a parallel resistive path.\n",
    "\n",
    "```text\n",
    "                   => i1 =>          ^\n",
    "        vi                v1        /        vo=0\n",
    "         +--------[ L ]--------[ R1 ]--------+\n",
    "         |                      /            |\n",
    "---------+                                   +--------\n",
    "         |                                   |\n",
    "         +-------------[ R2 ]----------------+\n",
    "                   => i2 =>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd553cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from aerosandbox.optimization.opti import Opti  # This is casadi\n",
    "import aerosandbox.numpy as anp\n",
    "import casadi as ca\n",
    "\n",
    "# This solver class will manage the expression graph,\n",
    "# use it to generate the function, Jacobian, and Hessian of the objective and constraints,\n",
    "# and hand them to an optimizer backend.\n",
    "solver: Opti = Opti()\n",
    "solver.solver(\"ipopt\")  # Use a general-purpose interior-point solver\n",
    "\n",
    "# Operating limits\n",
    "max_voltage = 1.0  # [V]\n",
    "max_current = 1e3  # [A]\n",
    "max_stored_energy = 12e3  # [J]\n",
    "max_dissipated_power = 200.0  # [W]\n",
    "\n",
    "# Physical parameters\n",
    "inductance = 0.1  # [H]\n",
    "#   [ohm] simple variable resistor that increases resistance with increasing current\n",
    "ref_current = 1.0  # [A]\n",
    "r1_func = lambda current: 3e-9 * (current / ref_current) ** 2 + 1e-6\n",
    "#   A normal resistor\n",
    "r2 = 0.01  # [ohm] parallel\n",
    "\n",
    "# Fixed time-grid\n",
    "n = 300\n",
    "time: ca.MX = solver.parameter(np.linspace(0.0, 100.0, n))\n",
    "\n",
    "# Decision variables\n",
    "terminal_voltage: ca.MX = solver.variable(np.zeros(n))  # [V] vi - vo\n",
    "i1: ca.MX = solver.variable(np.linspace(0.0, 100.0, n))  # [A] inductor current\n",
    "\n",
    "# Physics\n",
    "#   Lower path\n",
    "i2: ca.MX = terminal_voltage / r2  # [A] parallel current\n",
    "#   Upper path V = L*dI/dt + I*R(I)\n",
    "r1: ca.MX = r1_func(i1)  # Variable resistor\n",
    "inductor_voltage: ca.MX = inductance * solver.derivative_of(\n",
    "    i1, with_respect_to=time, derivative_init_guess=1.0, method=\"backward euler\"\n",
    ")  # V = L*dI/dt\n",
    "solver.subject_to((i1 * r1 + inductor_voltage) == terminal_voltage)\n",
    "#   Total\n",
    "terminal_current: ca.MX = i1 + i2\n",
    "stored_energy: ca.MX = 0.5 * inductance * i1**2  # [J]\n",
    "dissipated_power: ca.MX = i1**2 * r1 + i2**2 * r2  # [W]\n",
    "#   Initial conditions\n",
    "solver.subject_to(i1[0] == 0.0)\n",
    "solver.subject_to(i2[0] == 0.0)\n",
    "solver.subject_to(terminal_current[0] == 0.0)\n",
    "solver.subject_to(terminal_current >= 0.0)\n",
    "solver.subject_to(terminal_voltage >= 0.0)\n",
    "\n",
    "# Operating constraints\n",
    "solver.subject_to((terminal_current / max_current) ** 2 < 1.0)  # Smooth absolute value\n",
    "solver.subject_to((terminal_voltage / max_voltage) ** 2 < 1.0)\n",
    "solver.subject_to(stored_energy < max_stored_energy)  # These are always positive\n",
    "solver.subject_to(dissipated_power < max_dissipated_power)\n",
    "\n",
    "# Objective\n",
    "solver.maximize(anp.sum(i1**2))  # Charge inductor as quickly as possible\n",
    "\n",
    "# Solve the system\n",
    "sol = solver.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c760f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"paper\", font_scale=1.0)\n",
    "sns.set_style(\n",
    "    \"ticks\"\n",
    ")  # NOTE: Try other styles (white, whitegrid, ticks, dark, darkgrid)\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "\n",
    "def legend():\n",
    "    plt.legend(\n",
    "        loc=\"upper left\",  # Anchor upper left corner of legend box at bbox_to_anchor\n",
    "        bbox_to_anchor=(\n",
    "            1.0,\n",
    "            1.0,\n",
    "        ),  # Anchor here in normalized plot space relative to lower left corner\n",
    "        edgecolor=\"black\",  # Color of legend frame\n",
    "        fancybox=False,  # No rounded edges\n",
    "        borderaxespad=0,  # Set padding between legend and plot frame\n",
    "    )\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.title(\"Current [A]\")\n",
    "plt.xlabel(\"time [s]\")\n",
    "plt.plot(sol(time), sol(terminal_current), label=\"Terminal\")\n",
    "plt.plot(sol(time), sol(i1), label=\"Inductor\")\n",
    "plt.plot(sol(time), sol(i2), label=\"Parallel Path\")\n",
    "legend()\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.title(\"Normalized Limits\")\n",
    "plt.plot(sol(time), sol(terminal_voltage) / max_voltage, label=\"Voltage\")\n",
    "plt.plot(sol(time), sol(terminal_current) / max_current, label=\"Current\")\n",
    "plt.plot(\n",
    "    sol(time), sol(stored_energy) / max_stored_energy, label=\"Stored Energy\"\n",
    ")\n",
    "plt.plot(\n",
    "    sol(time),\n",
    "    sol(dissipated_power) / max_dissipated_power,\n",
    "    label=\"Dissipated Power\",\n",
    ")\n",
    "plt.xlabel(\"time [s]\")\n",
    "legend()\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.title(\"Variable Resistor [ohm]\")\n",
    "plt.plot(sol(time), sol(r1))\n",
    "plt.xlabel(\"time [s]\")\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.title(\"Stored Energy [J]\")\n",
    "plt.plot(sol(terminal_current), sol(stored_energy))\n",
    "plt.xlabel(\"terminal current [A]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d545a632",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### Symbolics\n",
    "\n",
    "`sympy` provides a powerful system for automating and cross-checking algebra and calculus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3507dbd0",
   "metadata": {},
   "source": [
    "##### Example: Symbolic Calculation of Lagrange Polynomial Coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bdd938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "import numpy as np\n",
    "\n",
    "# NOTE: Discuss relation to least-squares and maximum-likelihood fitting\n",
    "# NOTE: This is a special case of kernelized regression\n",
    "# specialized for (1) polynomial of order N\n",
    "# and for         (2) an exact solution (instead of least-squares)\n",
    "\n",
    "\n",
    "def lagrange_direct(grid: list[float] | list[sympy.Symbol], loc: float | sympy.Symbol):\n",
    "    \"\"\"\n",
    "    Develop minimum-order Lagrange polynomial interpolation stencil\n",
    "    for this grid to evaluate the interpolant at `loc` given some\n",
    "    values at each grid point.\n",
    "\n",
    "    Symbolic evaluation with integer exponents allows full-precision evaluation of the coefficients,\n",
    "    compared to the cumulative-product method which develops several steps of float roundoff.\n",
    "\n",
    "    Grid locations and the interpolation location `loc` can be either numeric or symbolic.\n",
    "    The values at the grid points are always symbolic and represented by `y_{i}` in the output.\n",
    "    \"\"\"\n",
    "    n = len(grid)  # Stencil size = polynomial order + 1\n",
    "    assert n < 10, \"This will not work well for extremely high-order polynomials\"\n",
    "\n",
    "    # Symbolic values at grid points\n",
    "    grid_vals = sympy.Matrix([sympy.symbols(f\"y_{i}\") for i in range(n)])\n",
    "\n",
    "    # Build square Vandermonde matrix\n",
    "    # [1 x0 x0^2 x0^3 ... x0^n-1]\n",
    "    # [     ...                 ]\n",
    "    # [1 xn xn^2 xn^3 ... xn^n-1]\n",
    "    # Small matrix, doesn't matter if we loop\n",
    "    a = np.zeros((n, n), dtype=object)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            a[i, j] = grid[i] ** j\n",
    "\n",
    "    amat = sympy.Matrix(a)\n",
    "\n",
    "    # Solve symbolic minimum-order polynomial coeffs\n",
    "    # We can take the direct inverse here because it's a square matrix,\n",
    "    # but if we were making a best-fit from a rectangular matrix, we'd use a pseudoinverse instead,\n",
    "    # which also works just fine in sympy\n",
    "    poly_coeffs = amat.inv() @ grid_vals\n",
    "\n",
    "    # Evaluate\n",
    "    # NOTE: If we were making a finite difference stencil, we could take\n",
    "    # the derivative w.r.t. a symbolic `loc` here!\n",
    "    # NOTE: We could also integrate w.r.t. a symbolic `loc` between two points\n",
    "    v = sum(\n",
    "        [poly_coeffs[i] * loc**i for i in range(n)]\n",
    "    )  # The interpolated value at `loc`\n",
    "\n",
    "    # Extract coefficients of resulting linear system\n",
    "    linear_coeffs = np.array([sympy.diff(v, gv) for gv in grid_vals])\n",
    "\n",
    "    return poly_coeffs, linear_coeffs, grid_vals, v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Show how result varies with changing loc, especially for integer values\n",
    "# NOTE: Explain why it's interesting that this turns polynomial interpolation into a dot product\n",
    "# NOTE: Explain why integration over a domain or differentiation at a point also produce a result of the same form\n",
    "\n",
    "# Symbolic inputs\n",
    "# grid = [sympy.symbols(f\"x_{i}\") for i in range(4)]\n",
    "# loc = sympy.symbols(\"loc\")\n",
    "\n",
    "# Numeric inputs\n",
    "grid = np.array([0.0, 0.8, 1.2, 3.0])\n",
    "loc = 0.5\n",
    "\n",
    "poly_coeffs, linear_coeffs, grid_vals, v = lagrange_direct(grid, loc)\n",
    "print(\"Symbolic interpolated value:\", v)\n",
    "print(\"Linear coeffs for polynomial interp:\", linear_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6ce8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual explanation -\n",
    "vals = np.random.uniform(-1.0, 1.0, grid.size)  # Values at grid points\n",
    "xobs = np.linspace(grid[0], grid[-1], 100)  # Observation points to examine\n",
    "coeffs = np.array(\n",
    "    [lagrange_direct(grid, x)[1] for x in xobs]\n",
    ")  # Interp coefficients for each point to examine\n",
    "yobs = coeffs @ vals  # Polynomial interpolation is a linear system now!\n",
    "\n",
    "plt.plot(xobs, yobs, color=\"k\", label=\"Fine observation points\")\n",
    "plt.scatter(grid, vals, color=\"r\", label=\"Control points\")\n",
    "plt.scatter(\n",
    "    [loc],\n",
    "    [np.dot(linear_coeffs, vals)],\n",
    "    color=\"b\",\n",
    "    marker=\"s\",\n",
    "    label=\"Observation at `loc`\",\n",
    ")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc718fb",
   "metadata": {},
   "source": [
    "----\n",
    "#### Fluid Properties\n",
    "\n",
    "Like electrons, but with a 2D space of flavors, and brutally nonlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8433c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CoolProp.CoolProp as cp\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fluid = \"Helium\"\n",
    "# fluid = \"REFPROP::HELIUM\"  # If we had refprop available\n",
    "# NOTE: CoolProp is missing supercritical Cp bump below 5.2K\n",
    "temp_range = [\n",
    "    6.0,\n",
    "    20.0,\n",
    "]  # [K], default range doesn't go as low temp as one would like\n",
    "pressure_range = [1e5, 35e5]  # [Pa]\n",
    "\n",
    "# Specific enthalpies in J/kg-K\n",
    "h_low: float = cp.PropsSI(\"H\", \"T\", temp_range[0], \"P\", pressure_range[0], fluid)\n",
    "h_high: float = cp.PropsSI(\"H\", \"T\", temp_range[1], \"P\", pressure_range[1], fluid)\n",
    "h_range = [h_low, h_high]\n",
    "\n",
    "# Grids & meshgrids\n",
    "n = 100\n",
    "pgrid = np.linspace(*pressure_range, n)\n",
    "hgrid = np.linspace(h_low, h_high, n)\n",
    "pmesh, hmesh = np.meshgrid(pgrid, hgrid, indexing=\"ij\")\n",
    "\n",
    "# Input names from http://www.coolprop.org/coolprop/HighLevelAPI.html#parameter-table\n",
    "prop_map = {\n",
    "    \"s\": \"S\",  # [J/kg-K] specific entropy\n",
    "    \"rho\": \"D\",  # [kg/m^3] mass density\n",
    "    \"mu\": \"VISCOSITY\",  # [Pa-s] dynamic viscosity\n",
    "    \"cp\": \"CPMASS\",  # [J/kg-K] specific heat at constant pressure\n",
    "    \"cv\": \"CVMASS\",  # [J/kg-K] specific heat at constant volume\n",
    "    \"Rm\": \"gas_constant\",  # [J/mol-K] molar gas constant\n",
    "    \"M\": \"molar_mass\",  # [kg/mol]\n",
    "    \"T\": \"T\",  # [K]\n",
    "    \"prandtl\": \"Prandtl\",  # [dimensionless]\n",
    "    \"k\": \"CONDUCTIVITY\",  # [W/m-K]\n",
    "}\n",
    "\n",
    "\n",
    "def phprop(p: float, h: float, prop: str) -> float:\n",
    "    \"\"\"Convenience function for scalar P-h lookup of a property on the selected fluid\"\"\"\n",
    "    return cp.PropsSI(prop_map[prop], \"P\", p, \"H\", h, fluid)\n",
    "\n",
    "\n",
    "def phtable(prop: str) -> NDArray:\n",
    "    \"\"\"Make a 2D P-h table of a property\"\"\"\n",
    "    out = np.zeros_like(pmesh.flatten())\n",
    "    for i, (p, h) in enumerate(zip(pmesh.flatten(), hmesh.flatten())):\n",
    "        out[i] = phprop(p, h, prop)\n",
    "    return out.reshape(pmesh.shape)\n",
    "\n",
    "\n",
    "# Realize tabulated properties on a grid\n",
    "prop_tables = {prop: phtable(prop) for prop in prop_map.keys()}\n",
    "\n",
    "# Add commonly-used derived values\n",
    "prop_tables[\"gamma\"] = (\n",
    "    prop_tables[\"cp\"] / prop_tables[\"cv\"]\n",
    ")  # [dimensionless] Ratio of specific heats\n",
    "prop_tables[\"R\"] = prop_tables[\"Rm\"] / prop_tables[\"M\"]  # [J/kg-K] Mass gas constant\n",
    "prop_tables[\"nu\"] = (\n",
    "    prop_tables[\"mu\"] / prop_tables[\"rho\"]\n",
    ")  # [m^2/s] Kinematic viscosity\n",
    "prop_tables[\"alpha\"] = np.sqrt(\n",
    "    prop_tables[\"gamma\"] * prop_tables[\"R\"] * prop_tables[\"T\"]\n",
    ")  # [m/s] speed of sound\n",
    "\n",
    "# Error on NaN and +/-Infinity values\n",
    "for k, v in prop_tables.items():\n",
    "    if not np.all(v == v):\n",
    "        raise ValueError(f\"Nonfinite value detected in `{k}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8609812",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(f\"Prandtl Number\\nTemp. Range {temp_range} [K]\")\n",
    "cs = plt.contour(pmesh, hmesh, prop_tables[\"prandtl\"], colors=\"k\")\n",
    "plt.clabel(cs, fmt=lambda x: f\"Pr={x:.3f}\")\n",
    "\n",
    "cs = plt.contour(pmesh, hmesh, prop_tables[\"T\"], linestyles=\"--\", colors=\"k\")\n",
    "plt.clabel(cs, fmt=lambda x: f\"T={x:.1f}K\")\n",
    "plt.xlabel(\"Pressure [Pa]\")\n",
    "plt.ylabel(\"Enthalpy [J/kg-K]\")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"Speed of Sound\\nTemp. Range {temp_range} [K]\")\n",
    "cs = plt.contour(pmesh, hmesh, prop_tables[\"alpha\"], colors=\"k\")\n",
    "plt.clabel(cs, fmt=lambda x: r\"$\\alpha$\" + f\"={x:.0f}m/s\")\n",
    "plt.xlabel(\"Pressure [Pa]\")\n",
    "plt.ylabel(\"Enthalpy [J/kg-K]\")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"Entropy\\nTemp. Range {temp_range} [K]\")\n",
    "cs = plt.contour(pmesh, hmesh, prop_tables[\"s\"], colors=\"k\")\n",
    "plt.clabel(cs, fmt=lambda x: f\"s={x:.1e} J/kg-K\")\n",
    "plt.xlabel(\"Pressure [Pa]\")\n",
    "plt.ylabel(\"Enthalpy [J/kg-K]\")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"Thermal Conductivity\\nTemp. Range {temp_range} [K]\")\n",
    "cs = plt.contour(pmesh, hmesh, prop_tables[\"k\"], colors=\"k\")\n",
    "plt.clabel(cs, fmt=lambda x: f\"k={x:.3f} W/m-K\")\n",
    "plt.xlabel(\"Pressure [Pa]\")\n",
    "plt.ylabel(\"Enthalpy [J/kg-K]\")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"Density\\nTemp. Range {temp_range} [K]\")\n",
    "cs = plt.contour(pmesh, hmesh, prop_tables[\"rho\"], colors=\"k\")\n",
    "plt.clabel(cs, fmt=lambda x: f\"rho={x:.1f} kg/m^3\")\n",
    "plt.xlabel(\"Pressure [Pa]\")\n",
    "plt.ylabel(\"Enthalpy [J/kg-K]\")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"Cp\\nTemp. Range {temp_range} [K]\")\n",
    "cs = plt.contour(pmesh, hmesh, prop_tables[\"cp\"], colors=\"k\")\n",
    "plt.clabel(cs, fmt=lambda x: f\"Cp={x:.1f} J/kg-K\")\n",
    "plt.xlabel(\"Pressure [Pa]\")\n",
    "plt.ylabel(\"Enthalpy [J/kg-K]\")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"Gamma\\nTemp. Range {temp_range} [K]\")\n",
    "cs = plt.contour(pmesh, hmesh, prop_tables[\"gamma\"], colors=\"k\")\n",
    "plt.clabel(cs, fmt=lambda x: f\"gamma={x:.1f} []\")\n",
    "plt.xlabel(\"Pressure [Pa]\")\n",
    "plt.ylabel(\"Enthalpy [J/kg-K]\")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"Viscosity\\nTemp. Range {temp_range} [K]\")\n",
    "cs = plt.contour(pmesh, hmesh, prop_tables[\"mu\"], colors=\"k\")\n",
    "plt.clabel(cs, fmt=lambda x: f\"mu={x:.1e} [Pa-s]\")\n",
    "plt.xlabel(\"Pressure [Pa]\")\n",
    "plt.ylabel(\"Enthalpy [J/kg-K]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848fe8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making differentiable fluid property tables for Casadi\n",
    "import casadi as ca\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "\n",
    "\n",
    "def cas_interp(name: str, grids: list[NDArray], vals: NDArray) -> ca.MX:\n",
    "    \"\"\"Build a differentiable B-spline interpolator\"\"\"\n",
    "    return ca.interpolant(name, \"bspline\", grids, vals.ravel(order=\"F\"))\n",
    "\n",
    "\n",
    "# Make interpolators over every property\n",
    "#  Casadi\n",
    "prop_cas_interps: dict[str, ca.MX] = {\n",
    "    prop: cas_interp(prop, [pgrid, hgrid], table) for prop, table in prop_tables.items()\n",
    "}\n",
    "#  Scipy\n",
    "prop_sp_interps: dict[str, RectBivariateSpline] = {\n",
    "    prop: RectBivariateSpline(pgrid, hgrid, table)\n",
    "    for prop, table in prop_tables.items()\n",
    "}\n",
    "\n",
    "# Check interpolators for consistency\n",
    "mid = (np.mean(pgrid), np.mean(hgrid))\n",
    "print(\"Differentiable interpolator:\", prop_cas_interps[\"T\"]([*mid]))\n",
    "print(\"Numeric interpolator:\", prop_sp_interps[\"T\"](*mid, grid=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35620f5d",
   "metadata": {},
   "source": [
    "#### Example: Subsonic Cold Helium Pipe Flow\n",
    "\n",
    "...ignoring entrance effects & assuming subsonic & no heat transfer\n",
    "\n",
    "with constant area\n",
    "\n",
    "fully-developed everywhere\n",
    "\n",
    "at steady-state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1790d916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Discuss rephrasing for design optimization and/or to include heat transfer\n",
    "# NOTE: Show discretization sensitivity\n",
    "# NOTE: Show sensitivity to inlet pressure & discuss tradeoff of incompressible static==stagnation assumption\n",
    "# NOTE: Discuss uncertainty in fluid properties\n",
    "import numpy as np\n",
    "from aerosandbox.optimization.opti import Opti\n",
    "import casadi as ca\n",
    "\n",
    "solver: Opti = Opti()\n",
    "solver.solver(\"ipopt\")\n",
    "\n",
    "# Problem setup\n",
    "# Using a small pressure delta to avoid creating a Fanno flow https://en.wikipedia.org/wiki/Fanno_flow\n",
    "length = 100.0  # [m] length of duct\n",
    "dh = 4e-3  # [m] hydraulic diameter\n",
    "print(f\"Hydraulic diameter: {dh:.4f}\")\n",
    "area = np.pi * (dh / 2) ** 2  # [m^2] duct flow area\n",
    "pi = 28e5  # [Pa] inlet stagnation pressure\n",
    "po = 14e5  # [Pa] outlet stagnation pressure\n",
    "ti = 15.0  # [K] inlet stagnation temperature\n",
    "# [J/kg] One stagnation enthalpy - isenthalpic flow (lossy without heat transfer)\n",
    "hi = cp.PropsSI(\"H\", \"T\", ti, \"P\", pi, fluid)\n",
    "roughness = 1e-6 / dh  # [dimensionless] relative roughness\n",
    "\n",
    "# Grid\n",
    "n = 100  # Number of segments\n",
    "xgrid = np.linspace(0.0, length, n)\n",
    "x: ca.MX = solver.parameter(xgrid)  # [m]\n",
    "\n",
    "# Decision variable\n",
    "mdot: ca.MX = solver.variable(0.01)  # [kg/s]\n",
    "p: ca.MX = solver.variable(np.linspace(pi, po, n))  # [Pa] stagnation pressure\n",
    "\n",
    "# Initialize enthalpy and static pressure\n",
    "ps: ca.MX = solver.variable(np.linspace(pi, po, n))  # [Pa] static pressure\n",
    "hs: ca.MX = solver.variable(hi * np.ones(n))  # [J/kg] static enthalpy\n",
    "\n",
    "# Thermo\n",
    "#   Section average relations\n",
    "h: ca.MX = solver.parameter(np.ones_like(xgrid) * hi)  # [J/kg] stagnation enthalpy\n",
    "rho: ca.MX = prop_cas_interps[\"rho\"](ca.hcat((ps, hs)).T).T  # [kg/m^3] static density\n",
    "q: ca.MX = mdot / rho  # [m^3/s] volumetric flowrate\n",
    "v: ca.MX = q / area  # [m/s] section average flow velocity\n",
    "\n",
    "#   Isentropic expansion from stagnation to static conditions\n",
    "solver.subject_to(ps == p - 0.5 * rho * v**2)  # Static pressure\n",
    "s: ca.MX = prop_cas_interps[\"s\"](ca.hcat((p, h)).T).T  # [J/kg-K] entropy\n",
    "ss: ca.MX = prop_cas_interps[\"s\"](ca.hcat((ps, hs)).T).T  # [J/kg-K] also entropy\n",
    "solver.subject_to(s == ss)  # Static entropy == stagnation entropy -> adiabatic process\n",
    "\n",
    "#   Friction pressure loss\n",
    "#   delta_p = f * (L/D) * rho * v^2 / 2\n",
    "#   dp/dx = f * (1/D) * rho * v^2 / 2\n",
    "mu: ca.MX = prop_cas_interps[\"mu\"](ca.hcat((ps, hs)).T).T  # [Pa-s] viscosity\n",
    "re: ca.MX = rho * v * dh / mu  # [dimensionless] reynolds number\n",
    "fx: ca.MX = (\n",
    "    -(f_bellos(re, roughness) / dh) * rho * v**2 / 2\n",
    ")  # [Pa/m] friction loss per meter\n",
    "solver.constrain_derivative(fx, p, x, method=\"trapezoid\")\n",
    "\n",
    "#   Boundary conditions\n",
    "solver.subject_to(p >= po)  # No negative pressures, thanks\n",
    "solver.subject_to(p[0] == pi)  # Boundary conditions\n",
    "solver.subject_to(p[-1] == po)\n",
    "\n",
    "# Instrumentation - we don't need these, we just want to see these values at the end\n",
    "temp: ca.MX = prop_cas_interps[\"T\"](ca.hcat((p, h)).T).T  # [K] stagnation temperature\n",
    "ts: ca.MX = prop_cas_interps[\"T\"](ca.hcat((ps, hs)).T).T  # [K] static temperature\n",
    "mach: ca.MX = (\n",
    "    v / prop_cas_interps[\"alpha\"](ca.hcat((p, h)).T).T\n",
    ")  # [dimensionless] mach number\n",
    "\n",
    "# We can solve with no objective purely to satisfy the constraints - this is common for physical systems\n",
    "# where the behavior is fully defined by conservation laws\n",
    "sol = solver.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3a06b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"mdot: {sol(mdot) * 1000.0:.2f} g/s\")\n",
    "\n",
    "plt.figure(figsize=(8, 2), dpi=200)\n",
    "plt.title(\"Pressure [Pa]\")\n",
    "plt.plot(xgrid, sol(ps), color=\"m\", linewidth=3, label=\"Interior Static\")\n",
    "plt.plot(xgrid, sol(p), color=\"k\", label=\"Interior Stagnation\")\n",
    "plt.axhline(pi, alpha=0.4, color=\"r\", label=\"Inlet Stagnation\")\n",
    "plt.axhline(po, alpha=0.4, color=\"b\", label=\"Outlet Stagnation\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(8, 2), dpi=200)\n",
    "plt.title(\"Velocity [m/s]\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.plot(xgrid, sol(v), color=\"k\")\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.title(\"Re\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.plot(xgrid, sol(re), color=\"k\")\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.title(\"Density\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.plot(xgrid, sol(rho), color=\"k\")\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.title(\"Temperature\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.plot(xgrid, sol(ts), color=\"m\", linewidth=4, label=\"static\")\n",
    "plt.plot(xgrid, sol(temp), color=\"k\", label=\"stagnation\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.title(\"Mach Number\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.plot(xgrid, sol(mach), color=\"k\")\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.title(\"p / rho\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.plot(xgrid, sol(p) / sol(rho), color=\"k\")\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.title(\"enthalpy\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.plot(xgrid, sol(hs), color=\"k\", label=\"static\")\n",
    "plt.plot(xgrid, sol(h), color=\"b\", label=\"stagnation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04a263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
